{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchsde\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from torch import _vmap_internals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "\n",
    "# Binary classification\n",
    "X = X[~(y==2)][:,[0,1]]\n",
    "y = y[~(y==2)]\n",
    "\n",
    "# dummy dims \n",
    "X = np.concatenate((torch.ones(X.shape[0],1), torch.tensor(X) ), axis=1)\n",
    "\n",
    "names = iris['target_names']\n",
    "feature_names = iris['feature_names']\n",
    "\n",
    "# Scale data to have mean 0 and variance 1 \n",
    "# which is importance for convergence of the neural network\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data set into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=2)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    torch.tensor(X_train, dtype=torch.float32, device=device), \\\n",
    "    torch.tensor(X_test, dtype=torch.float32, device=device), \\\n",
    "    torch.tensor(y_train, dtype=torch.float32, device=device), \\\n",
    "    torch.tensor(y_test, dtype=torch.float32, device=device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7AAAAF1CAYAAADRBwbsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfXhddZnv/89turUbhMaBnhnalAcdDQ9tpbB5dkSpGoQCVRHhiFpwDqIzrR4OGc0MU/hVj5wxKsqMg6OCZQSRTInRMmqQKgIzUtwhbVKmBnRkaBJGKpjY6q6m4f79sXbaJuRpJXvttdbe79d15UrXvZ7u79qX2E/X2t9l7i4AAAAAAJLuJXE3AAAAAADAdBBgAQAAAACpQIAFAAAAAKQCARYAAAAAkAoEWAAAAABAKhBgAQAAAACpEHmANbMaM+s0s3vHWfcGMxs0sy3Fn7VR9wMAAAAASKc5ZTjHhyVtl3ToBOsfcvcVZegDAAAAAJBikQZYM6uTdL6k/yvpmlIc8/DDD/ejjz66FIcCAAAAACRMR0fHr9x9/njror4D+zlJfyXpkEm2OcPMtkrql3Stuz8+2QGPPvpo5fP5ErYIAAAAAEgKM/uvidZF9h1YM1sh6Vl375hks8ckHeXur5X095LaJjjWVWaWN7P8zp07I+gWAAAAAJB0UU7idJakC83sKUnfkHSOmd1x4Abu/ht3313883ckZczs8LEHcvcvuXvO3XPz5497JxkAAAAAUOEiC7Du3uTude5+tKRLJf3A3S8/cBsz+xMzs+KfTy3281xUPQEAAAAA0qscsxCPYmZXS5K7f1HSxZI+aGZ7JRUkXeruXu6eAAAAAGAqQ0ND6u3t1Z49e+JupSLMnTtXdXV1ymQy097H0pYXc7mcM4kTAAAAgHL7xS9+oUMOOUSHHXaYig+SYobcXc8995x27dqlY445ZtQ6M+tw99x4+0X5HVgAAAAAqBh79uwhvJaImemwww4LfTebAAsAAAAA00R4LZ2ZXEsCLAAAAABUoPXr16u/vz/uNkqq7JM4AQAAAEA1aOvsU3N7j/oHClpQm1VjQ71WLltYtvOvX79eixcv1oIFC8p2zqhxBxYAgJRp6+zTWf/vBzrmY/+qs/7fD9TW2Rd3SwCAMdo6+9TU2q2+gYJcUt9AQU2t3bP+b/Zvf/tbnX/++Xrta1+rxYsX6+6771ZHR4fOPvtsnXzyyWpoaNAzzzyjDRs2KJ/P693vfrdOPPFEFQoFbdq0ScuWLdOSJUt05ZVX6ve//70k6WMf+5iOP/54LV26VNdee60kaePGjTrttNO0bNkyvelNb9Ivf/nL2V6SkiDAAgCQIlH9hQgAUFrN7T0qDA2PqhWGhtXc3jOr437ve9/TggULtHXrVm3btk3nnnuuVq9erQ0bNqijo0NXXnml/uZv/kYXX3yxcrmc7rzzTm3ZskVmplWrVunuu+9Wd3e39u7dq1tuuUXPP/+8vvnNb+rxxx9XV1eXrrvuOknS6173Oj3yyCPq7OzUpZdeqk996lOz6rtUCLAAAKRIVH8hAgCUVv9AIVR9upYsWaL7779fH/3oR/XQQw9px44d2rZtm9785jfrxBNP1Cc+8Qn19va+aL+enh4dc8wxes1rXiNJet/73qcHH3xQhx56qObOnas///M/V2trqw466CBJUm9vrxoaGrRkyRI1Nzfr8ccfn1XfpUKABQAgRaL6CxEAoLQW1GZD1afrNa95jTo6OrRkyRI1NTXpnnvu0QknnKAtW7Zoy5Yt6u7u1n333fei/dx93OPNmTNHjz76qN7xjneora1N5557riRp9erV+su//Et1d3frn/7pn0K/7iYqBFgAAFIkqr8QAQBKq7GhXtlMzahaNlOjxob6WR23v79fBx10kC6//HJde+212rx5s3bu3Kkf//jHkqShoaF9d0sPOeQQ7dq1S5J07LHH6qmnntLPfvYzSdLXvvY1nX322dq9e7cGBwd13nnn6XOf+5y2bNkiSRocHNTChcGEU7fffvusei4lZiEGACBFGhvq1dTaPeox4lL8hQgAUFojsw2Xehbi7u5uNTY26iUveYkymYxuueUWzZkzR2vWrNHg4KD27t2rj3zkIzrhhBO0atUqXX311cpms/rxj3+sr371q3rnO9+pvXv36pRTTtHVV1+t559/XhdddJH27Nkjd9dNN90kSbrhhhv0zne+UwsXLtTpp5+uX/ziF7O+JqVgE91KTqpcLuf5fD7uNgAAiE3cr2UAgGq1fft2HXfccXG3UVHGu6Zm1uHuufG25w4sAAAps3LZQgIrAKAq8R1YAAAAAEAqEGABAAAAAKlAgAUAAAAApAIBFgAAAACQCgRYAAAAAEAqEGABAAAAoIqtXbtW999/f+j9HnjgAa1YsSKCjibGa3QAAAAAIApdLdKmddJgrzSvTlq+Vlp6SSytuLvcXS95yYvvYa5bt64sPezdu1dz5swugnIHFgAAAABKratF2rhGGtwhyYPfG9cE9Vn46Ec/qn/8x3/ct3zDDTfoM5/5jJqbm3XKKado6dKluv766yVJTz31lI477jh96EMf0kknnaQdO3Zo1apVWrx4sZYsWaKbbrpJkrRq1Spt2LBBkvSTn/xEZ555pl772tfq1FNP1a5du7Rnzx5dccUVWrJkiZYtW6Yf/vCHL+rr+eef18qVK7V06VKdfvrp6urq2tffVVddpbe85S1673vfO6uxSwRYAAAAACi9TeukocLo2lAhqM/CpZdeqrvvvnvfcktLi+bPn68nn3xSjz76qLZs2aKOjg49+OCDkqSenh69973vVWdnp371q1+pr69P27ZtU3d3t6644opRx/7DH/6gd73rXfr85z+vrVu36v7771c2m9UXvvAFSVJ3d7fuuusuve9979OePXtG7Xv99ddr2bJl6urq0ic/+clRYbWjo0Pf+ta39PWvf31WY5d4hBgAAAAASm+wN1x9mpYtW6Znn31W/f392rlzp17xileoq6tL9913n5YtWyZJ2r17t5588kkdeeSROuqoo3T66adLkl75ylfqP//zP7V69Wqdf/75estb3jLq2D09PTriiCN0yimnSJIOPfRQSdLDDz+s1atXS5KOPfZYHXXUUXriiSdG7fvwww/rnnvukSSdc845eu655zQ4OChJuvDCC5XNZmc17hEEWAAAAAAotXl1xceHx6nP0sUXX6wNGzbov//7v3XppZfqqaeeUlNTkz7wgQ+M2u6pp57SwQcfvG/5Fa94hbZu3ar29nZ94QtfUEtLi2677bZ9691dZvai87n7lD2Nt83IsQ7sYbZ4hBgAAAAASm35Wikz5q5jJhvUZ+nSSy/VN77xDW3YsEEXX3yxGhoadNttt2n37t2SpL6+Pj377LMv2u9Xv/qVXnjhBb3jHe/Qxz/+cT322GOj1h977LHq7+/XT37yE0nSrl27tHfvXr3+9a/XnXfeKUl64okn9PTTT6u+vn7Uvgdu88ADD+jwww/fdwe3lLgDCwAAAAClNjLbcASzEJ9wwgnatWuXFi5cqCOOOEJHHHGEtm/frjPOOEOS9PKXv1x33HGHampqRu3X19enK664Qi+88IIk6cYbbxy1/qUvfanuvvturV69WoVCQdlsVvfff78+9KEP6eqrr9aSJUs0Z84crV+/Xi972ctG7XvDDTfoiiuu0NKlS3XQQQfp9ttvn/U4x2PTuR2cJLlczvP5fNxtAAAAAKgy27dv13HHHRd3GxVlvGtqZh3unhtvex4hBgAAAACkAgEWAAAAAJAKBFgAAAAAQCowiRMAACXU1tmn5vYe9Q8UtKA2q8aGeq1ctjDutgAAJTLRq2YQ3kzmY+IOLAAAJdLW2aem1m71DRTkkvoGCmpq7VZbZ1/crQEASmDu3Ll67rnnZhS8MJq767nnntPcuXND7ccdWAAASqS5vUeFoeFRtcLQsJrbe7gLCwAVoK6uTr29vdq5c2fcrVSEuXPnqq6uLtQ+BFgAAEqkf6AQqg4ASJdMJqNjjjkm7jaqGo8QAwBQIgtqs6HqAAAgHAIsAAAl0thQr2ymZlQtm6lRY0N9TB0BAFBZeIQYAIASGfmeK7MQAwAQDQIsAAAltHLZQgIrAAAR4RFiAAAAAEAqEGABAAAAAKlAgAUAAAAApAIBFgAAAACQCgRYAAAAAEAqMAsxACC12jr7eGUNAABVhAALAEilts4+NbV2qzA0LEnqGyioqbVbkgixAABUKB4hBgCkUnN7z77wOqIwNKzm9p6YOgIAAFEjwAIAUql/oBCqDgAA0o8ACwBIpQW12VB1AACQfgRYAEAqNTbUK5upGVXLZmrU2FAfU0cAACBqTOIEAEilkYmamIUYAIDqQYAFAKTWymULCawAAFQRHiEGAAAAAKQCARYAAAAAkAoEWAAAAABAKkQeYM2sxsw6zezecdaZmd1sZj8zsy4zOynqfgAAAAAA6VSOSZw+LGm7pEPHWfdWSa8u/pwm6ZbibwAAUCJtnX3M1gwAqAiR3oE1szpJ50v6ygSbXCTpnz3wiKRaMzsiyp4AAKgmbZ19amrtVt9AQS6pb6CgptZutXX2xd0aAAChRf0I8eck/ZWkFyZYv1DSjgOWe4s1AABQAs3tPSoMDY+qFYaG1dzeE1NHAADMXGQB1sxWSHrW3Tsm22ycmo9zrKvMLG9m+Z07d5asRwAAKl3/QCFUHQCAJIvyDuxZki40s6ckfUPSOWZ2x5hteiUtOmC5TlL/2AO5+5fcPefuufnz50fVLwAAFWdBbTZUHQCAJIsswLp7k7vXufvRki6V9AN3v3zMZt+W9N7ibMSnSxp092ei6gkAgGrT2FCvbKZmVC2bqVFjQ31MHQEAMHPlmIV4FDO7WpLc/YuSviPpPEk/k/Q7SVeUux8AACrZyGzDzEIMAKgE5v6ir5wmWi6X83w+H3cbAAAAAIAImFmHu+fGWxf1LMQAAAAAAJQEARYAAAAAkAoEWAAAAABAKhBgAQAAAACpUPZZiAEASJPr2rp11+YdGnZXjZkuO22RPrFySdxtAQBQlQiwAABM4Lq2bt3xyNP7lofd9y0TYgEAKD8eIQYAYAJ3bd4Rqg4AAKJFgAUAYALDE7wrfaI6AACIFgEWAIAJ1JiFqgMAgGgRYAEAmMBlpy0KVQcAANFiEicAACYwMlETsxADAJAM5in7Hk8ul/N8Ph93GwAAAACACJhZh7vnxlvHI8QAAAAAgFQgwAIAAAAAUoEACwAAAABIBQIsAAAAACAVCLAAAAAAgFTgNToAgMR495d/rH/7+fP7ls961R/pzv91RowdJVNbZ5+a23vUP1DQgtqsGhvqtXLZwrjbAgAgctyBBQAkwtjwKkn/9vPn9e4v/zimjpKprbNPTa3d6hsoyCX1DRTU1Nqtts6+uFsDACByBFgAQCKMDa9T1atVc3uPCkPDo2qFoWE1t/fE1BEAAOVDgAUAIEX6Bwqh6gAAVBICLAAAKbKgNhuqDgBAJSHAAgAS4axX/VGoerVqbKhXNlMzqpbN1KixoT6mjgAAKB8CLAAgEe78X2e8KKwyC/GLrVy2UDe+fYkW1mZlkhbWZnXj25cwCzEAoCqYu8fdQyi5XM7z+XzcbQAAAAAAImBmHe6eG28dd2ABAAAAAKlAgAUAAAAApAIBFgAAAACQCgRYAAAAAEAqzIm7AQAARrR19qm5vUf9AwUtqM2qsaG+pLPrzuT4UfcEAACmjwALAEiEts4+NbV2qzA0LEnqGyioqbVbkkoSGGdy/Kh7AgAA4fAIMQAgEZrbe/YFxRGFoWE1t/fEdvyoewIAAOEQYAEAidA/UAhVL8fxo+4JAACEQ4AFACTCgtpsqHo5jh91TwAAIBwCLAAgERob6pXN1IyqZTM1amyoj+34UfcEAADCYRInAEAijEyKFNWMvzM5ftQ9AQCAcMzd4+4hlFwu5/l8Pu42AAAAAAARMLMOd8+Nt45HiAEAAAAAqUCABQAAAACkAgEWAAAAAJAKBFgAAAAAQCowCzEAJFBbZ1/iZr4N21MSxwAAANKNAAsACdPW2aem1m4VhoYlSX0DBTW1dktSbAEwbE9JHAMAAEg/HiEGgIRpbu/ZF/xGFIaG1dzeE1NH4XtK4hgAAED6EWABIGH6Bwqh6uUQtqckjgEAAKQfARYAEmZBbTZUvRzC9pTEMQAAgPQjwAJAwjQ21CubqRlVy2Zq1NhQH1NH4XtK4hgAAED6MYkTACTMyCRHSZrBN2xPSRwDAABIP3P3uHsIJZfLeT6fj7sNAAAAAEAEzKzD3XPjreMRYgAAAABAKhBgAQAAAACpQIAFAAAAAKQCARYAAAAAkApTzkJsZjlJfyZpgaSCpG2S7nf356fYb66kByW9rHieDe5+/Zht3iDpW5J+USy1uvu6kGMAAAAAAFSBCQOsma2StEZBuOyQ1CNprqTXSfqomW2T9Lfu/vQEh/i9pHPcfbeZZSQ9bGbfdfdHxmz3kLuvmOU4AAAJc11bt+7avEPD7qox02WnLdInVi4p6T5tnX2Je1VPEnsCAKBSTHYH9mBJZ7l7YbyVZnaipFdLGjfAevB+nt3FxUzxJ13v7AEAzMh1bd2645H9//cw7L5veaJAGnafts4+NbV2qzA0LEnqGyioqbVbkmILjEnsCQCASjLhd2Dd/QsThdfi+i3uvmmyg5tZjZltkfSspO+7++ZxNjvDzLaa2XfN7IRpdw4ASKy7Nu8IVZ/JPs3tPfuC4ojC0LCa23um2WXpJbEnAAAqyXS+A3uMpNWSjj5we3e/cKp93X1Y0olmVivpm2a22N23HbDJY5KOKj5mfJ6kNgV3dcf2cJWkqyTpyCOPnOq0AICYDfv4D9xMVJ/JPv0D4/8b60T1ckhiTwAAVJLpzELcJukpSX8v6TMH/Eybuw9IekDSuWPqv3H33cU/f0dSxswOH2f/L7l7zt1z8+fPD3NqAEAMasxC1Weyz4LabKh6OSSxJwAAKsl0Auwed7/Z3X/o7j8a+ZlqJzObX7zzKjPLSnqTpJ+O2eZPzIK/mZjZqcV+ngs9CgBAolx22qJQ9Zns09hQr2ymZlQtm6lRY0P9NLssvST2BABAJZnyEWJJnzez6yXdp2BmYUmSuz82xX5HSLrdzGoUBNMWd7/XzK4u7v9FSRdL+qCZ7VXwip5Li5M/AQBSbGTSpTAzCofdZ2RSpCTN+JvEngAAqCQ2VV40sxslvUfSzyW9UCy7u58TcW/jyuVyns/n4zg1AAAAACBiZtbh7rnx1k3nDuzbJL3S3f9Q2rYAAAAAAJi+6XwHdquk2qgbAQAAAABgMtO5A/vHkn5qZj/R6O/ATvkaHQAAAAAASmU6Afb6yLsAAAAAAGAK0wmwT0t6xt33SPteifPHkXYFAFWurbMv8plsr2vrDjVLcDmOH3bclXCdKkZXi7RpnTTYK82rk5avlZZeEndXAIAKM50A+y+SzjxgebhYOyWSjgCgyrV19qmptVuFoWFJUt9AQU2t3ZJUsnB2XVu37njk6X3Lw+77lksRzmZy/LDjroTrVDG6WqSNa6ShQrA8uCNYlgixAICSms4kTnMOnIG4+OeXRtcSAFS35vaefaFsRGFoWM3tPSU7x12bd4Sql+P4YcddCdepYmxatz+8jhgqBHUAAEpoOgF2p5ntm7DJzC6S9KvoWgKA6tY/UAhVn4nhCd4BPlG9HMcPO+5KuE4VY7A3XB0AgBmaToC9WtJfm9nTZva0pI9KuiratgCgei2ozYaqz0SNWah6OY4fdtyVcJ0qxry6cHUAAGZoygDr7j9399MlHS/pBHc/091/Hn1rAFCdGhvqlc3UjKplMzVqbKgv2TkuO21RqHo5jh923JVwnSrG8rVSZsw/HGSyQR0AgBKacBInM7tc0tfd/QVJcvfdY9a/StIR7v5wtC0CQHUZmYAoytl1RyYgimp23ZkcP+y4K+E6VYyRiZqYhRgAEDHzCb7HY2YflnSlpI7iz05JcyX9qaSzFXwP9mPu/mR5Wg3kcjnP5/PlPCUAAAAAoEzMrMPdc+Otm/AOrLt/3sz+QdI5ks6StFRSQdJ2Se9x96cn2hcAAAAAgFKb9D2w7j4s6fvFHwAAAAAAYjOdWYgBAAAAAIgdARYAAAAAkAqTPkIMAMBMtXX2hZ4heCb7ABPqamFmZACoMFMGWDN7maR3SDr6wO3dfV10bQEA0qyts09Nrd0qDA1LkvoGCmpq7ZakCQPpTPYBJtTVIm1cIw0VguXBHcGyRIgFgBSbziPE35J0kaS9kn57wA8AAONqbu/ZF0RHFIaG1dzeU9J9gAltWrc/vI4YKgR1AEBqTecR4jp3PzfyTgAAFaN/oBCqPtN9gAkN9oarAwBSYTp3YP/dzJZE3gkAoGIsqM2Gqs90H2BC8+rC1QEAqTBhgDWzbjPrkvQ6SY+ZWY+ZdR1QBwBgXI0N9cpmakbVspkaNTbUl3QfYELL10qZMf/4kckGdQBAak32CPGKsnUBAKgoI5MuhZlReCb7ABMamaiJWYgBoKKYu0++gdnX3P09U9XKJZfLeT6fj+PUAAAAAICImVmHu+fGWzed78CeMOZgNZJOLkVjAAAAAABM12TfgW0ys12SlprZb4o/uyQ9q+DVOgAAAAAAlM2EAdbdb3T3QyQ1u/uhxZ9D3P0wd28qY48AAAAAAEw8iZOZnVT8478c8Od93P2xyLoCAAAAAGCMyWYh/kzx91xJOUlbJZmkpZI2K3i9DgAAAAAAZTFhgHX3N0qSmX1D0lXu3l1cXizp2vK0BwDJ09bZF/mrXsKe47q2bt21eYeG3VVjpstOW6RPrFxS0p7CKsd1QkS6Wqrz9TPVOu6wuE4AYjTZHdgRx46EV0ly921mdmKEPQFAYrV19qmptVuFoWFJUt9AQU2twX8iSxXOwp7jurZu3fHI0/uWh933LccVYstxnRCRrhZp4xppqBAsD+4IlqXKDinVOu6wuE4AYjad1+hsN7OvmNkbzOxsM/uypO1RNwYASdTc3rMvlI0oDA2rub0ntnPctXlHqHo5lOM6ISKb1u0PJyOGCkG9klXruMPiOgGI2XTuwF4h6YOSPlxcflDSLZF1BAAJ1j9QCFUvxzmG3UPVy6Ec1wkRGewNV68U1TrusLhOAGI25R1Yd9/j7je5+9uKPze5+55yNAcASbOgNhuqXo5z1JiFqpdDOa4TIjKvLly9UlTruMPiOgGI2YQB1sxair+7zaxr7E/5WgSA5GhsqFc2UzOqls3UqLGhPrZzXHbaolD1cijHdUJElq+VMmP+oSGTDeqVrFrHHRbXCUDMJnuEeOSR4RXlaAQA0mBkAqIoZ9cNe46RiZqSNAtxOa4TIjIyEU+1zTJbreMOi+sEIGbmU3xHysyulPSQuz9ZnpYml8vlPJ/Px90GAAAAACACZtbh7rnx1k1nEqejJV1uZkdJ6pD0kIJAu6V0LQIAAAAAMLnpTOK01t3PkbRY0sOSGhUEWQAAAAAAymbKO7Bmdp2ksyS9XFKnpGsV3IUFAAAAAKBspvMI8dsl7ZX0r5J+JOkRXqMDAAAAACi3KQOsu59kZodIep2kN0v6spn90t1fF3l3AFCl2jr7Ip/BN+w5rmvrTtRMx0BVuPcaqWO95MOS1Ugnr5JWfLa05+hqYVZhAKkxnUeIF0v6M0lnS8pJ2iEeIQaAyLR19qmptVuFoWFJUt9AQU2t3ZJUshAb9hzXtXXrjkee3rc87L5vmRALROTea6T8rfuXfXj/cqlCbFeLtHGNNFQIlgd3BMsSIRZAIk05iZOkv5N0iKSbJR3n7m90d95WDQARaW7v2RcsRxSGhtXc3hPbOe7avCNUHUAJdKwPV5+JTev2h9cRQ4WgDgAJNJ1HiM8vRyMAgED/QCFUvRznGJ7gneET1QGUgA+Hq8/EYG+4OgDEbDp3YAEAZbSgNhuqXo5z1JiFqgMoAasJV5+JeXXh6gAQMwIsACRMY0O9spnRf0HNZmrU2FAf2zkuO21RqDqAEjh5Vbj6TCxfK2XG/MNVJhvUASCBpvMaHQBAGY1MohTlLMRhzzEyUROzEANlNDJRU5SzEI9M1MQsxABSwnyC7y+Z2UZJE365yd0vjKqpyeRyOc/n83GcGgAAAAAQMTPrcPfceOsmuwP76Yj6AQAAAAAgtAkDrLv/qJyNAAAAAAAwmSm/A2tmr5Z0o6TjJc0dqbv7KyPsCwAAAACAUaYzC/FXJd0iaa+kN0r6Z0lfi7IpAAAAAADGms4sxFl332Rm5u7/JekGM3tI0vWT7WRmcyU9KOllxfNscPfrx2xjkj4v6TxJv5O0yt0fm8E4AGDG2jr7Qs34G3b7pLqurTvUrMLVep3U1RLtDK33XhN+ltmoe4r6+OU6RxKFHXe1XicAmMB0AuweM3uJpCfN7C8l9Un6H9PY7/eSznH33WaWkfSwmX3X3R85YJu3Snp18ec0BXd6Tws1AgCYhbbOPjW1dqswNCxJ6hsoqKm1W5LGDVtht0+q69q6dccjT+9bHnbftzxeiK3W66SuFmnjGmmoECwP7giWpdKEiHuvkfK37l/24f3LE4XYqHuK+vjlOkcShR13tV4nAJjEdB4h/oikgyStkXSypPdIet9UO3lgd3ExU/wZ+1qeiyT9c3HbRyTVmtkR020eAGarub1nX8gaURgaVnN7T0m2T6q7Nu8IVa/W66RN6/aHhxFDhaBeCh3rw9XL0VPUxy/XOZIo7Lir9ToBwCSmvAPr7j+RpOJd2DXuvmu6BzezGkkdkv5U0hfcffOYTRZKOvBvS73F2jNjjnOVpKsk6cgjj5zu6QFgSv0DhUjrSTU8wTvAJ6pX63XSYG+4elg+HK4+2blL1VPUxy/XOZIo7Lir9ToBwCSmvANrZjkz65bUJanbzLaa2cnTObi7D7v7iZLqJJ1qZovHHn683cY5zpfcPefuufnz50/n1AAwLQtqs5HWk6rGxvvP78T1ar1OmlcXrh6W1YSrT3buUvUU9fHLdY4kCjvuar1OADCJ6TxCfJukD7n70e5+tKS/UDAz8bS5+4CkBySdO2ZVr6RFByzXSeoPc2wAmI3GhnplM6PDQjZTo8aG+pJsn2qDN9EAABc1SURBVFSXnbYoVL1ar5OWr5UyY0J3JhvUS+HkVeHq5egp6uOX6xxJFHbc1XqdAGAS0wmwu9z9oZEFd39Y0pSPEZvZfDOrLf45K+lNkn46ZrNvS3qvBU6XNOjuzwgAymTlsoW68e1LtLA2K5O0sDarG9++ZMKJhsJun1SfWLlEl59+5L47rjVmuvz0Iyechbhar5OWXiJdcLM0b5EkC35fcHPpJtBZ8Vkp9/79d1ytJliebBbiqHuK+vjlOkcShR13tV4nAJiE+QTfd9q3gdlNCiZxukvB473vkvRrSfdI0kSvvTGzpZJul1SjICi3uPs6M7u6uN8Xi6/R+QcFd2Z/J+kKd89P1k8ul/N8ftJNAAAAAAApZWYd7p4bd900AuwPJ1nt7n7ObJoLiwALAAAAAJVrsgA7nVmI31j6lgAAAAAACGc6sxD/sZndambfLS4fb2bvj741AAAAAAD2m84kTusltUtaUFx+QtJHomoIAAAAAIDxTCfAHu7uLZJekCR33ytpkjesAwAAAABQelN+B1bSb83sMAUzEGvkdTeRdgUACdbW2afm9h71DxS0oDarxob69L0eBsnR1SJtWicN9krz6oJ3fE71mpSZ7BO1sD0lcdzluK5J/OwAIEWmE2CvUfC+1leZ2b9Jmi/p4ki7AoCEauvsU1NrtwpDwYMofQMFNbV2SxIhFuF1tUgb10hDhWB5cEewLE0camayT9TC9pTEcZfjuibxswOAlJnyEeLie17PlnSmpA9IOsHdu6JuDACSqLm9Z194HVEYGlZze09MHSHVNq3bH2ZGDBWCein3iVrYnpI47nJc1yR+dgCQMtOZhfidkrLu/riklZLuNrOTIu8MABKof6AQqg5MarA3XH2m+0QtbE9JHHc5rmsSPzsASJnpTOL0t+6+y8xeJ6lB0u2Sbom2LQBIpgW12VB1YFLz6sLVZ7pP1ML2lMRxl+O6JvGzA4CUmU6AHXlW7nxJt7j7tyS9NLqWACC5Ghvqlc3UjKplMzVqbKiPqSOk2vK1UmbMP35kskG9lPtELWxPSRx3Oa5rEj87AEiZ6QTYPjP7J0mXSPqOmb1smvsBQMVZuWyhbnz7Ei2szcokLazN6sa3L2ECJ8zM0kukC26W5i2SZMHvC26efEKfmewTtbA9JXHc5biuSfzsACBlzN0n38DsIEnnSup29yfN7AhJS9z9vnI0OFYul/N8Ph/HqQEAAAAAETOzDnfPjbduytfouPvvJLUesPyMpGdK1x4AAAAAAFPjUWAAAAAAQCoQYAEAAAAAqUCABQAAAACkwpTfgQUAAAlz7zVSx3rJhyWrkU5eJa34bNxdhVMJY5CkrhZp0zppsDd4n+vytfHPKpzEngCgRAiwAACkyb3XSPlb9y/78P7ltATAShiDFATFjWukoUKwPLgjWJbiC4xJ7AkASohHiAEASJOO9eHqSVQJY5CCu5wjQXHEUCGoxyWJPQFACRFgAQBIEx8OV0+iShiDFDyiG6ZeDknsCQBKiAALAECaWE24ehJVwhik4PulYerlkMSeAKCECLAAAKTJyavC1ZOoEsYgBZMjZbKja5lsUI9LEnsCgBIiwAIAkCYrPivl3r//bqXVBMtpmvyoEsYgBZMiXXCzNG+RJAt+X3BzvJMlJbEnACghc/e4ewgll8t5Pp+Puw0AAAAAQATMrMPdc+Ot4w4sAAAAACAVCLAAAAAAgFQgwAIAAAAAUoEACwAAAABIhTlxNwAAwIx1tUib1kmDvcF7LpevTd9sq+UYw73XSB3rJR8OZvw9eVXpZ/ythM8CAJB4BFgAQDp1tUgb10hDhWB5cEewLKUnOJVjDPdeI+Vv3b/sw/uXSxViK+GzAACkAo8QAwDSadO6/YFpxFAhqKdFOcbQsT5cfSYq4bMAAKQCARYAkE6DveHqSVSOMfhwuPpMVMJnAQBIBQIsACCd5tWFqydROcZgNeHqM1EJnwUAIBUIsACAdFq+VspkR9cy2aCeFuUYw8mrwtVnohI+CwBAKhBgAQDptPQS6YKbpXmLJFnw+4Kb0zVpUDnGsOKzUu79+++4Wk2wXMpZiCvhswAApIK5e9w9hJLL5Tyfz8fdBgAAAAAgAmbW4e658dZxBxYAAAAAkAoEWAAAAABAKhBgAQAAAACpQIAFAAAAAKQCARYAAAAAkAoEWAAASqmrRbppsXRDbfC7qyX+c5SjJwAAymBO3A0AAFAxulqkjWukoUKwPLgjWJZK907UsOcoR08AAJQJd2ABACiVTev2B8URQ4WgHtc5ytETAABlQoAFAKBUBnvD1ctxjnL0BABAmRBgAQAolXl14erlOEc5egIAoEwIsAAAlMrytVImO7qWyQb1uM5Rjp4AACgTAiwAAKWy9BLpgpuleYskWfD7gptLO1lS2HOUoycAAMrE3D3uHkLJ5XKez+fjbgMAAAAAEAEz63D33HjruAMLAAAAAEgFAiwAAAAAIBUIsAAAAACAVIgswJrZIjP7oZltN7PHzezD42zzBjMbNLMtxR+mRAQAAAAAjGtOhMfeK+n/uPtjZnaIpA4z+767/8eY7R5y9xUR9gEASIuuFmnTOmmwN3hP6fK16ZstN+wYKmHMScW1BYCKE1mAdfdnJD1T/PMuM9suaaGksQEWAIAgbGxcIw0VguXBHcGylJ7QEXYMlTDmpOLaAkBFKst3YM3saEnLJG0eZ/UZZrbVzL5rZieUox8AQAJtWrc/bIwYKgT1tAg7hkoYc1JxbQGgIkX5CLEkycxeLukeSR9x99+MWf2YpKPcfbeZnSepTdKrxznGVZKukqQjjzwy4o4BALEY7A1XT6KwY6iEMScV1xYAKlKkd2DNLKMgvN7p7q1j17v7b9x9d/HP35GUMbPDx9nuS+6ec/fc/Pnzo2wZABCXeXXh6kkUdgyVMOak4toCQEWKchZik3SrpO3u/tkJtvmT4nYys1OL/TwXVU8AgARbvlbKZEfXMtmgnhZhx1AJY04qri0AVKQoHyE+S9J7JHWb2ZZi7a8lHSlJ7v5FSRdL+qCZ7ZVUkHSpu3uEPQEAkmpkYp00zxobdgyVMOak4toCQEWytOXFXC7n+Xw+7jYAAAAAABEwsw53z423riyzEAMAAAAAMFsEWAAAAABAKhBgAQAAAACpQIAFAAAAAKQCARYAAAAAkApRvkYHAFBJulp4Jcl03HuN1LFe8mHJaqSTV0krxn0dOgAACIkACwCYWleLtHGNNFQIlgd3BMsSIfZA914j5W/dv+zD+5cJsQAAzBqPEAMAprZp3f7wOmKoENSxX8f6cHUAABAKARYAMLXB3nD1auXD4eoAACAUAiwAYGrz6sLVq5XVhKsDAIBQCLAAgKktXytlsqNrmWxQx34nrwpXBwAAoRBgAQBTW3qJdMHN0rxFkiz4fcHNTOA01orPSrn377/jajXBMhM4AQBQEubucfcQSi6X83w+H3cbAAAAAIAImFmHu+fGW8cdWAAAAABAKhBgAQAAAACpQIAFAAAAAKQCARYAAAAAkApz4m4AAKpBW2efmtt71D9Q0ILarBob6rVy2cK424pWV4u0aZ002Bu8L3b52uqYtbhax51EfBYAUHEIsAAQsbbOPjW1dqswNCxJ6hsoqKm1W5IqN8R2tUgb10hDhWB5cEewLFV2gKjWcScRnwUAVCQeIQaAiDW39+wLryMKQ8Nqbu+JqaMy2LRuf3AYMVQI6pWsWsedRHwWAFCRCLAAELH+gUKoekUY7A1XrxTVOu4k4rMAgIpEgAWAiC2ozYaqV4R5deHqlaJax51EfBYAUJEIsAAQscaGemUzNaNq2UyNGhvqY+qoDJavlTJjAnomG9QrWbWOO4n4LACgIjGJEwBEbGSipqqahXhkkpxqmwG2WsedRHwWAFCRzN3j7iGUXC7n+Xw+7jYAAAAAABEwsw53z423jkeIAQAAAACpQIAFAAAAAKQCARYAAAAAkAoEWAAAAABAKhBgAQDA7HW1SDctlm6oDX53taTzHACAROM1OgAAYHa6WqSNa6ShQrA8uCNYlkr32ppynAMAkHjcgQUAALOzad3+YDliqBDU03QOAEDiEWABAMDsDPaGqyf1HACAxCPAAgCA2ZlXF66e1HMAABKPAAsAAGZn+Vopkx1dy2SDeprOAQBIPAIsAACYnaWXSBfcLM1bJMmC3xfcXNrJlcpxDgBA4pm7x91DKLlczvP5fNxtAAAAAAAiYGYd7p4bbx13YAEAAAAAqUCABQAAAACkAgEWAAAAAJAKBFgAAAAAQCoQYAEAAAAAqUCABQAAAACkAgEWAAAAAJAKBFgAAAAAQCoQYAEAAAAAqUCABQAAAACkAgEWAAAAAJAKBFgAAAAAQCoQYAEAAAAAqUCABQAAAACkAgEWAAAAAJAKBFgAAAAAQCpEFmDNbJGZ/dDMtpvZ42b24XG2MTO72cx+ZmZdZnZSVP0AAAAAANItyjuweyX9H3c/TtLpkv7CzI4fs81bJb26+HOVpFsi7AcAUE5dLdJNi6UbaoPfXS1xdwQAAFIusgDr7s+4+2PFP++StF3SwjGbXSTpnz3wiKRaMzsiqp4AAGXS1SJtXCMN7pDkwe+NawixAABgVsryHVgzO1rSMkmbx6xaKGnHAcu9enHIBQCkzaZ10lBhdG2oENQBAABmKPIAa2Yvl3SPpI+4+2/Grh5nFx/nGFeZWd7M8jt37oyiTQBAKQ32hqsDAABMQ6QB1swyCsLrne7eOs4mvZIWHbBcJ6l/7Ebu/iV3z7l7bv78+dE0CwAonXl14eoAAADTEOUsxCbpVknb3f2zE2z2bUnvLc5GfLqkQXd/JqqeAABlsnytlMmOrmWyQR0AAGCG5kR47LMkvUdSt5ltKdb+WtKRkuTuX5T0HUnnSfqZpN9JuiLCfgAA5bL0kuD3pnXBY8Pz6oLwOlIHAACYAXN/0VdOEy2Xy3k+n4+7DQAAAABABMysw91z460ryyzEAAAAAADMFgEWAAAAAJAKBFgAAAAAQCoQYAEAAAAAqUCABQAAAACkAgEWAAAAAJAKBFgAAAAAQCoQYAEAAAAAqUCABQAAAACkAgEWAAAAAJAK5u5x9xCKme2U9F9x94FIHC7pV3E3gbLh864efNbVhc+7evBZVxc+7+qRhM/6KHefP96K1AVYVC4zy7t7Lu4+UB583tWDz7q68HlXDz7r6sLnXT2S/lnzCDEAAAAAIBUIsAAAAACAVCDAIkm+FHcDKCs+7+rBZ11d+LyrB591deHzrh6J/qz5DiwAAAAAIBW4AwsAAAAASAUCLGJnZnPN7FEz22pmj5vZ/xd3T4iWmdWYWaeZ3Rt3L4iWmT1lZt1mtsXM8nH3g+iYWa2ZbTCzn5rZdjM7I+6eEA0zqy/+b3rk5zdm9pG4+0I0zOx/F/9+ts3M7jKzuXH3hOiY2YeLn/XjSf3fNY8QI3ZmZpIOdvfdZpaR9LCkD7v7IzG3hoiY2TWScpIOdfcVcfeD6JjZU5Jy7h73++QQMTO7XdJD7v4VM3uppIPcfSDuvhAtM6uR1CfpNHf/r7j7QWmZ2UIFfy873t0LZtYi6Tvuvj7ezhAFM1ss6RuSTpX0B0nfk/RBd38y1sbG4A4sYueB3cXFTPGHf1mpUGZWJ+l8SV+JuxcApWFmh0p6vaRbJcnd/0B4rRrLJf2c8FrR5kjKmtkcSQdJ6o+5H0TnOEmPuPvv3H2vpB9JelvMPb0IARaJUHykdIukZyV93903x90TIvM5SX8l6YW4G0FZuKT7zKzDzK6KuxlE5pWSdkr6avHrAV8xs4Pjbgplcamku+JuAtFw9z5Jn5b0tKRnJA26+33xdoUIbZP0ejM7zMwOknSepEUx9/QiBFgkgrsPu/uJkuoknVp8hAEVxsxWSHrW3Tvi7gVlc5a7nyTprZL+wsxeH3dDiMQcSSdJusXdl0n6raSPxdsSolZ8VPxCSf8Sdy+Ihpm9QtJFko6RtEDSwWZ2ebxdISruvl3S30n6voLHh7dK2htrU+MgwCJRio+cPSDp3JhbQTTOknRh8XuR35B0jpndEW9LiJK79xd/Pyvpmwq+V4PK0yup94CnZzYoCLSobG+V9Ji7/zLuRhCZN0n6hbvvdPchSa2Szoy5J0TI3W9195Pc/fWSnpeUqO+/SgRYJICZzTez2uKfswr+Y/nTeLtCFNy9yd3r3P1oBY+d/cDd+ZfcCmVmB5vZISN/lvQWBY8nocK4+39L2mFm9cXSckn/EWNLKI/LxOPDle5pSaeb2UHFSTeXS9oec0+IkJn9j+LvIyW9XQn83/icuBsAJB0h6fbiTIYvkdTi7rxeBUi/P5b0zeDvPJoj6evu/r14W0KEVku6s/hY6X9KuiLmfhCh4vfj3izpA3H3gui4+2Yz2yDpMQWPknZK+lK8XSFi95jZYZKGJP2Fu/867obG4jU6AAAAAIBU4BFiAAAAAEAqEGABAAAAAKlAgAUAAAAApAIBFgAAAACQCgRYAAAAAEAqEGABACgxM3uDmb3odWAT1UtwvpVmdvwByw+YWW4a+x1Rin6K7/PmFUkAgMgRYAEASL+Vko6fcqsXu0bSl2d7cnffKekZMztrtscCAGAyBFgAQNUxs4PN7F/NbKuZbTOzdxXrJ5vZj8ysw8zazeyIYv0BM/ucmf17cftTi/VTi7XO4u/6kD3cZmY/Ke5/UbG+ysxazex7ZvakmX3qgH3eb2ZPFPv5spn9g5mdKelCSc1mtsXMXlXc/J1m9mhx+z+boI13SPpe8dg1ZvZpM+s2sy4zW12sP2VmnzSzH5tZ3sxOKl6bn5vZ1Qccq03Su6c7fgAAZmJO3A0AABCDcyX1u/v5kmRm88wsI+nvJV3k7juLofb/SrqyuM/B7n6mmb1e0m2SFkv6qaTXu/teM3uTpE8qCIXT8TeSfuDuV5pZraRHzez+4roTJS2T9HtJPWb295KGJf2tpJMk7ZL0A0lb3f3fzezbku519w3F8UjSHHc/1czOk3S9pDcdeHIzO0bSr93998XSVZKOkbSsOJ4/OmDzHe5+hpndJGm9pLMkzZX0uKQvFrfJS/rENMcOAMCMEGABANWoW9KnzezvFAS/h8xssYJQ+v1iAKyR9MwB+9wlSe7+oJkdWgydh0i63cxeLcklZUL08BZJF5rZtcXluZKOLP55k7sPSpKZ/YekoyQdLulH7v58sf4vkl4zyfFbi787JB09zvojJO08YPlNkr7o7nuL43z+gHXfLv7ulvRyd98laZeZ7TGzWncfkPSspAWTDxkAgNkhwAIAqo67P2FmJ0s6T9KNZnafpG9Ketzdz5hot3GWPy7ph+7+NjM7WtIDIdowSe9w955RRbPTFNx5HTGs4P+vLcSxdcAxRvYfq6AgNB/Yz9gxjj3WC2N6e+GAY88tHhMAgMjwHVgAQNUxswWSfufud0j6tILHcnskzTezM4rbZMzshAN2G/me7OskDRbvkM6T1FdcvypkG+2SVlvxdq+ZLZti+0clnW1mrzCzORr9qPIuBXeDw3hCo+/M3ifp6uKxNeYR4ul4jaRtIfcBACAUAiwAoBotUfCd0y0Kvov6CXf/g6SLJf2dmW2VtEXSmQfs82sz+3cF3/l8f7H2KQV3cP9NwSPHYXxcwSPHXWa2rbg8IXfvU/Ad282S7pf0H5IGi6u/IamxOBnUqyY4xNjj/VbSz83sT4ulr0h6utjPVkn/M+R43ijpX0PuAwBAKOY+0dNCAABACmYhlnStu+dj7uPl7r67eJf0m5Juc/dvzuJ4b5N0srtfV4LeHlQwAdavZ3ssAAAmwh1YAADS44biXeNtkn6h4NU1M1YMv0/Ntikzmy/ps4RXAEDUuAMLAAAAAEgF7sACAAAAAFKBAAsAAAAASAUCLAAAAAAgFQiwAAAAAIBUIMACAAAAAFKBAAsAAAAASIX/H1BVFWTDvKPrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, figsize=(16, 6))\n",
    "for target, target_name in enumerate(names[0:2]):\n",
    "    X_plot = X[y == target]\n",
    "    ax1.plot(X_plot[:, 1], X_plot[:, 2], \n",
    "             linestyle='none', \n",
    "             marker='o', \n",
    "             label=target_name)\n",
    "ax1.set_xlabel(feature_names[0])\n",
    "ax1.set_ylabel(feature_names[1])\n",
    "ax1.axis('equal')\n",
    "ax1.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim=1):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        # an affine operation: y = Wx + b\n",
    "        \n",
    "        self.nn = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_dim, 20), torch.nn.ReLU(),\n",
    "            torch.nn.Linear(20, 20), torch.nn.ReLU(),\n",
    "            torch.nn.Linear(20, input_dim)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.nn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SDE(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, state_size=1, brownian_size=1, batch_size=10, γ=1.0):\n",
    "        super().__init__()\n",
    "        self.noise_type = 'scalar'\n",
    "        self.sde_type = 'ito'\n",
    "        \n",
    "        self.state_size = state_size\n",
    "        self.brownian_size = brownian_size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.γ = γ\n",
    "        self.μ = Net(input_dim=state_size).to(device)\n",
    "\n",
    "    # Drift\n",
    "    def f(self, t, y):\n",
    "        return self.μ(y)  # shape (batch_size, state_size)\n",
    "\n",
    "    # Diffusion\n",
    "    def g(self, t, y):\n",
    "        return (torch.ones_like(y).to(device) * self.γ)[:, :, None]\n",
    "\n",
    "\n",
    "# sde = SDE(state_size, brownian_size, batch_size, 1).to(device)\n",
    "# y0 = torch.full((batch_size, state_size), 0.1).to(device)\n",
    "\n",
    "# Initial state y0, the SDE is solved over the interval [ts[0], ts[-1]].\n",
    "# ys will have shape (t_size, batch_size, state_size)\n",
    "# ts = torch.linspace(0, 1, t_size).to(device)\n",
    "# ys = torchsde.sdeint(sde, y0, ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\DeclareMathOperator*{\\argmin}{arg\\,min}$$\n",
    "$$\\def\\E{{\\mathbb{E}}}$$\n",
    "$$\\def\\rvu{{\\mathbf{u}}}$$\n",
    "$$\\def\\rvTheta{{\\bm{\\Theta}}}$$\n",
    "$$\\def\\gU{{\\mathcal{U}}}$$\n",
    "$$\\def\\mX{{\\mathbf{X}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controlled Schrodinger Follmer Sampler\n",
    "\n",
    "The objevtive we are trying to implement is:\n",
    "\n",
    "\\begin{align}\n",
    "  \\mathbf{u}_t^{*}=  \\argmin_{\\rvu_t \\in \\mathcal{U}}\\mathbb{E}\\left[\\frac{1}{2\\gamma}\\int_0^1||\\rvu(t, \\Theta_t)||^2 dt - \\ln\\left(\\frac{ p(\\mX | \\Theta_1)p(\\Theta_1)}{\\mathcal{N}(\\Theta_1|\\mathbf{0}, \\gamma \\mathbb{I} )}\\right)\\right] \\\n",
    "\\end{align}\n",
    "\n",
    "Where:\n",
    "\\begin{align}\n",
    "d\\Theta_t = \\rvu(t, \\Theta_t)dt + \\sqrt{\\gamma} dB_t\n",
    "\\end{align}\n",
    "\n",
    "To do so we use the EM discretisation. However results are a bit strange. The weights sampled at $\\Theta_1^{\\mathbf{u}^*}$ are too large (despite the perfect predictive accuracy). So something is off. Its as though the girsanov factor is failing to regularize the model. This needs more investigation.\n",
    "\n",
    "### Note on the bug\n",
    "\n",
    "I have a MAP baseline implemented further down. It seems to be the case that the map baseline is also converging to similar large values as the CSF sampler so whatever the bug is its in both places. \n",
    "\n",
    "### Maybe there is no bug\n",
    "\n",
    "I just tweakted $p(\\theta)$ to be much more confident and now the weights are much smaller which is expected behaviour and we see the same behaviour in MAP. So maybe there is no bug , I still find that when $\\sigma_w=1$ the prior is having less effect than I would expect so stil not completely sure we are bug free. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_g(Θ, ln_prior, ln_like, γ=1.0):\n",
    "    \"\"\"\n",
    "    g function in control objective\n",
    "    \n",
    "    g is the Radon-Nikodym derivtive between\n",
    "    the joint and N(0, γ I)\n",
    "    \"\"\"\n",
    "    normal_term = -0.5 * (Θ**2).sum(axis=1) / γ\n",
    "    return ln_like(Θ) + 1.0 *( ln_prior(Θ)- normal_term)\n",
    "\n",
    "def log_likelihood(Θ, X, y):\n",
    "    \"\"\"\n",
    "    Slow implementation of logistic log likleihood\n",
    "    as a function of the parameters\n",
    "    \"\"\"\n",
    "#     import pdb; pdb.set_trace()\n",
    "    logits = X.mm(Θ.T)\n",
    "    \n",
    "    # pos_weights = torch.ones(logits.shape[0]*logits.shape[1], device=device)\n",
    "    # loss = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weights, reduction=\"sum\")\n",
    "    # loss = torch.nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "    \n",
    "    # Should reimplement BCEWithLogitsLoss with logsumexp from scratch\n",
    "    # since this next line the .repeat is extremely inneficient\n",
    "    # vector_loss = loss(logits.reshape(-1), y.reshape(-1,1).repeat(1, logits.shape[1]).reshape(-1))\n",
    "    vector_loss = - (torch.einsum(\"a,ab->b\", y, torch.nn.functional.logsigmoid(logits)) +\n",
    "                     torch.einsum(\"a,ab->b\", (1-y), torch.log(1-torch.sigmoid(logits)))\n",
    "                    )\n",
    "    return vector_loss\n",
    "\n",
    "def log_likelihood_vmap(Θ, X, y):\n",
    "    \"\"\"\n",
    "    Hoping this implementation is less buggy / faster\n",
    "    \n",
    "    still feels a bit slow.\n",
    "    \"\"\"\n",
    "#     import pdb; pdb.set_trace()\n",
    "    logits = X.mm(Θ.T)\n",
    "    \n",
    "    pos_weights = torch.ones(logits.shape[0], device=device)\n",
    "    loss = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weights, reduction=\"sum\")\n",
    "    \n",
    "    loss_ = lambda x: loss(x, y)\n",
    "    \n",
    "    # Should reimplement BCEWithLogitsLoss with logsumexp from scratch\n",
    "    # since this next line the .repeat is extremely inneficient\n",
    "#     import pdb; pdb.set_trace()\n",
    "    batched_loss =  torch._vmap_internals.vmap(loss_)\n",
    "#     vector_loss = torch.vmap(loss_, logits).sum()\n",
    "#     import pdb; pdb.set_trace()\n",
    "    return batched_loss(logits.T)\n",
    "\n",
    "def gaussian_prior(Θ, σ_w=1.0):\n",
    "    return -0.5 * (Θ**2).sum(axis=1) / σ_w\n",
    "\n",
    "def relative_entropy_control_cost(sde, Θ_0, X, y, ln_prior, ln_like, Δt=0.05, γ=1.0):\n",
    "    \"\"\"\n",
    "    Objective for the Hamilton-Bellman-Jacobi Follmer Sampler\n",
    "    \"\"\"\n",
    "    n = int(1.0 / Δt)\n",
    "    ts = torch.linspace(0, 1, n).to(device)\n",
    "    \n",
    "    ln_like_partial = lambda Θ: ln_like(Θ, X, y)\n",
    "    \n",
    "    Θs =  torchsde.sdeint(sde, Θ_0, ts, method=\"euler\",dt=Δt)\n",
    "    μs = sde.f(ts, Θs)\n",
    "    ΘT = Θs[-1] \n",
    "    lng = log_g(ΘT, ln_prior, ln_like_partial, γ)\n",
    "    girsanov_factor = (0.5 / γ) * ((μs**2).sum(axis=-1)).sum(axis=0)\n",
    "    \n",
    "    return (girsanov_factor - lng).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Δt=0.05\n",
    "t_size = int(math.ceil(1.0/Δt))\n",
    "\n",
    "dim = 3\n",
    "\n",
    "ts = torch.linspace(0, 1, t_size).to(device)\n",
    "no_posterior_samples = 50\n",
    "\n",
    "sde = SDE(dim, dim, no_posterior_samples, 1.0).to(device)\n",
    "Θ_0 = torch.zeros((no_posterior_samples, dim)).to(device) # Θ_0 ~ δ_0\n",
    "# Initial state y0, the SDE is solved over the interval [ts[0], ts[-1]].\n",
    "# ys will have shape (t_size, batch_size, state_size)\n",
    "ys = torchsde.sdeint(sde, Θ_0, ts, dt=Δt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-169.3880, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def log_g(Θ, ln_prior, ln_like, γ=1.0):\n",
    "    \"\"\"\n",
    "    g function in control objective\n",
    "    \n",
    "    g is the Radon-Nikodym derivtive between\n",
    "    the joint and N(0, γ I)\n",
    "    \"\"\"\n",
    "    normal_term = -0.5 * (Θ**2).sum(axis=1) / γ\n",
    "#     import pdb; pdb.set_trace()\n",
    "    return ln_like(Θ) + ( ln_prior(Θ)- normal_term)\n",
    "\n",
    "relative_entropy_control_cost(sde, Θ_0, X_train, y_train, \n",
    "                              gaussian_prior, log_likelihood_vmap, γ=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae8267f7845840d6b3e740a9752dc7d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vargf\\anaconda3\\lib\\site-packages\\torch\\_vmap_internals.py:252: UserWarning: torch.vmap is an experimental prototype that is subject to change and/or deletion. Please use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vargf\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2582: UserWarning: Batching rule not implemented for aten::binary_cross_entropy_with_logits falling back to slow (for loop and stack) implementation (Triggered internally at  ..\\aten\\src\\ATen\\BatchedFallback.cpp:63.)\n",
      "  return torch.binary_cross_entropy_with_logits(input, target, weight, pos_weight, reduction_enum)\n"
     ]
    }
   ],
   "source": [
    "γ = 1.0\n",
    "Δt=0.05\n",
    "t_size = int(math.ceil(1.0/Δt))\n",
    "print(t_size)\n",
    "ts = torch.linspace(0, 1, t_size).to(device)\n",
    "\n",
    "sde = SDE(dim, dim, no_posterior_samples  , γ=γ).to(device)\n",
    "optimizer = torch.optim.Adam(sde.μ.parameters(), lr=0.05, weight_decay =1)\n",
    "#     optimizer = torch.optim.LBFGS(gpr.parameters(), lr=0.01)\n",
    "losses = []\n",
    "num_steps = 100\n",
    "for i in tqdm(range(num_steps)):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if isinstance(optimizer, torch.optim.LBFGS):\n",
    "        def closure():\n",
    "            loss = relative_entropy_control_cost(\n",
    "                sde, Θ_0.float(),\n",
    "                X_train.float(), y_train.float(),\n",
    "                gaussian_prior, log_likelihood_vmap, γ=γ\n",
    "            )\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            return loss\n",
    "\n",
    "        optimizer.step(closure)\n",
    "        losses.append(closure().item())\n",
    "    else:\n",
    "        loss = relative_entropy_control_cost(\n",
    "            sde, Θ_0,\n",
    "            X_train, y_train,\n",
    "            gaussian_prior, log_likelihood_vmap, γ=γ\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-64.98429870605469,\n",
       " -93.38932037353516,\n",
       " -130.50546264648438,\n",
       " -89.58368682861328,\n",
       " -154.3239288330078,\n",
       " -143.3965606689453,\n",
       " -141.76124572753906,\n",
       " -135.87791442871094,\n",
       " -143.93344116210938,\n",
       " -149.88726806640625,\n",
       " -153.63824462890625,\n",
       " -162.69583129882812,\n",
       " -163.77194213867188,\n",
       " -166.3619842529297,\n",
       " -166.3121795654297,\n",
       " -164.67437744140625,\n",
       " -166.94656372070312,\n",
       " -167.96542358398438,\n",
       " -168.85769653320312,\n",
       " -168.98919677734375,\n",
       " -168.4539794921875,\n",
       " -167.669677734375,\n",
       " -169.19390869140625,\n",
       " -170.4196014404297,\n",
       " -170.27542114257812,\n",
       " -170.88510131835938,\n",
       " -170.83128356933594,\n",
       " -170.7919158935547,\n",
       " -169.6811065673828,\n",
       " -170.09706115722656,\n",
       " -171.00677490234375,\n",
       " -170.4223175048828,\n",
       " -170.6701202392578,\n",
       " -170.48097229003906,\n",
       " -170.93414306640625,\n",
       " -171.39608764648438,\n",
       " -171.79995727539062,\n",
       " -170.63601684570312,\n",
       " -170.57264709472656,\n",
       " -170.57704162597656,\n",
       " -170.4522247314453,\n",
       " -171.33819580078125,\n",
       " -170.7266387939453,\n",
       " -170.61929321289062,\n",
       " -170.87139892578125,\n",
       " -171.09677124023438,\n",
       " -170.9167938232422,\n",
       " -171.51773071289062,\n",
       " -172.29249572753906,\n",
       " -170.59214782714844,\n",
       " -170.46836853027344,\n",
       " -170.5786895751953,\n",
       " -170.66421508789062,\n",
       " -170.6044921875,\n",
       " -171.55067443847656,\n",
       " -171.59132385253906,\n",
       " -169.585693359375,\n",
       " -170.19175720214844,\n",
       " -171.27566528320312,\n",
       " -171.56008911132812,\n",
       " -171.4497833251953,\n",
       " -170.5402374267578,\n",
       " -170.20118713378906,\n",
       " -171.71034240722656,\n",
       " -170.42083740234375,\n",
       " -170.90980529785156,\n",
       " -170.2757568359375,\n",
       " -170.947998046875,\n",
       " -172.46249389648438,\n",
       " -169.93931579589844,\n",
       " -170.38449096679688,\n",
       " -171.01605224609375,\n",
       " -171.33596801757812,\n",
       " -170.7217559814453,\n",
       " -170.9413299560547,\n",
       " -171.34690856933594,\n",
       " -171.17654418945312,\n",
       " -170.0149383544922,\n",
       " -170.02345275878906,\n",
       " -172.5056610107422,\n",
       " -171.46597290039062,\n",
       " -171.55722045898438,\n",
       " -172.3787078857422,\n",
       " -170.1403045654297,\n",
       " -171.81358337402344,\n",
       " -170.1889190673828,\n",
       " -170.69972229003906,\n",
       " -170.82432556152344,\n",
       " -170.72373962402344,\n",
       " -172.0522003173828,\n",
       " -171.4161834716797,\n",
       " -172.05177307128906,\n",
       " -171.7578887939453,\n",
       " -171.6162872314453,\n",
       " -170.88400268554688,\n",
       " -171.4763641357422,\n",
       " -171.55435180664062,\n",
       " -170.88099670410156,\n",
       " -171.62803649902344,\n",
       " -171.4515838623047]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x255a9119130>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 50, 3])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " torchsde.sdeint(sde, Θ_0, ts, method=\"euler\", dt=Δt).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 3])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Θ_1 = torchsde.sdeint(sde, Θ_0, ts, dt=Δt)[-1,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4.,  2.,  4., 14.,  9.,  8.,  4.,  3.,  1.,  1.]),\n",
       " array([0.72255677, 1.2040005 , 1.6854442 , 2.166888  , 2.6483316 ,\n",
       "        3.1297753 , 3.6112192 , 4.092663  , 4.5741067 , 5.05555   ,\n",
       "        5.536994  ], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1,ax2,ax3) = plt.subplots(1,3)\n",
    "\n",
    "ax1.hist(Θ_1[:,0].cpu().detach().numpy())\n",
    "ax2.hist(Θ_1[:,1].cpu().detach().numpy())\n",
    "ax3.hist(Θ_1[:,2].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.sigmoid(X_train.mm(Θ_1.T)).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9875, device='cuda:0')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((pred < 0.5).float() == y_train).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = torch.sigmoid(X_test.float().mm(Θ_1.T)).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((pred_test < 0.5).float() == y_test).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0691, -2.6474,  2.7917], device='cuda:0', grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Θ_1.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "         1., 1.], device='cuda:0'),\n",
       " tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test, (pred_test < 0.5).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAP Baseline\n",
    "\n",
    "We run the point estimate approximation (Maximum a posteriori) to double check what the learned weights look like.  We get the  exact same training accuracy as with the controlled model and similarly large weights for the non bias weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b020534120e43338eed0cb71250bbc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking arugment for argument mat2 in method wrapper_mm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15490/2703831245.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mlosses_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mloss_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_likelihood_vmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mΘ_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgaussian_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mΘ_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15490/296078900.py\u001b[0m in \u001b[0;36mlog_likelihood_vmap\u001b[0;34m(Θ, X, y)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \"\"\"\n\u001b[1;32m     37\u001b[0m \u001b[0;31m#     import pdb; pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mΘ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mpos_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking arugment for argument mat2 in method wrapper_mm)"
     ]
    }
   ],
   "source": [
    "Θ_map = torch.full((1, dim), 0.0, requires_grad=True)  \n",
    "optimizer_map = torch.optim.Adam([Θ_map], lr=0.05)\n",
    "#     optimizer = torch.optim.LBFGS(gpr.parameters(), lr=0.01)\n",
    "\n",
    "losses_map = []\n",
    "num_steps = 1000\n",
    "for i in tqdm(range(num_steps)):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if isinstance(optimizer_map, torch.optim.LBFGS):\n",
    "        def closure_map():\n",
    "            loss_map = log_likelihood_vmap()\n",
    "            optimizer_map.zero_grad()\n",
    "            loss_map.backward()\n",
    "            return loss\n",
    "\n",
    "        optimizer_map.step(closure_map)\n",
    "        losses_map.append(closure_map().item())\n",
    "    else:\n",
    "        loss_map = -(log_likelihood_vmap(Θ_map, (X_train).float(), (y_train).float()) + gaussian_prior(Θ_map))\n",
    "        optimizer_map.zero_grad()\n",
    "        loss_map.backward()\n",
    "\n",
    "        optimizer_map.step()\n",
    "        losses_map.append(loss.item())\n",
    "\n",
    "Θ_map\n",
    "pred_map = torch.sigmoid(X_train.float().mm(Θ_map.T)).mean(axis=1)\n",
    "((pred_map < 0.5).float() == y_train).float().mean(), Θ_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pyro Bayesian Logistic Regeression\n",
    "\n",
    "As a baseline we run pyro with SVI on this same example atm we get very different results which is a bit worrying.\n",
    "\n",
    "#### EDIT:\n",
    "\n",
    "I think results are actually in agreement what was happening is the priors in the pyro code where much more confident thus the smaller weights. I just tried changing the prior of this pyro model and the posterior is not changing much, this is a bit fishy maybe worth investigating. \n",
    "\n",
    "I think it might just be the case that this model is not very good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special as ssp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributions.constraints as constraints\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam, SGD\n",
    "\n",
    "pyro.enable_validation(True)\n",
    "torch.set_default_dtype(torch.double) # this was necessary on the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# these were adapted from the Pyro VAE tutorial\n",
    "\n",
    "def train(svi, train_loader, n_train):\n",
    "    # initialize loss accumulator\n",
    "    epoch_loss = 0.\n",
    "    # do a training epoch over each mini-batch x returned\n",
    "    # by the data loader\n",
    "    for _, xs in enumerate(train_loader):\n",
    "        # do ELBO gradient and accumulate loss\n",
    "        epoch_loss += svi.step(*xs)\n",
    "\n",
    "    # return epoch loss\n",
    "    total_epoch_loss_train = epoch_loss / n_train\n",
    "    return total_epoch_loss_train\n",
    "\n",
    "\n",
    "def evaluate(svi, test_loader, n_test):\n",
    "    # initialize loss accumulator\n",
    "    test_loss = 0.\n",
    "    # compute the loss over the entire test set\n",
    "    for _, xs in enumerate(test_loader):\n",
    "        # compute ELBO estimate and accumulate loss\n",
    "        test_loss += svi.evaluate_loss(*xs)\n",
    "\n",
    "    total_epoch_loss_test = test_loss / n_test\n",
    "    return total_epoch_loss_test\n",
    "\n",
    "\n",
    "def plot_llk(train_elbo, test_elbo, test_int):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    x = np.arange(len(train_elbo))\n",
    "\n",
    "    plt.plot(x, train_elbo, marker='o', label='Train ELBO')\n",
    "    plt.plot(x[::test_int], test_elbo, marker='o', label='Test ELBO')\n",
    "    plt.xlabel('Training Epoch')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressionModel(nn.Module):\n",
    "    def __init__(self, p):\n",
    "        super(LogRegressionModel, self).__init__()\n",
    "        \n",
    "        self.p = p\n",
    "\n",
    "        # hyperparameters for normal priors\n",
    "        self.alpha_h_loc = torch.zeros(1, p)\n",
    "        self.alpha_h_scale = 0.0001 * torch.ones(1, p)\n",
    "        self.beta_h_loc = torch.zeros(1)\n",
    "        self.beta_h_scale =  0.0001 * torch.ones(1)\n",
    "        \n",
    "        # initial values of variational parameters\n",
    "        self.alpha_0 = np.zeros((1, p))\n",
    "        self.alpha_0_scale = np.ones((1, p))\n",
    "        self.beta_0 = np.zeros((1,))\n",
    "        self.beta_0_scale = np.ones((1,))\n",
    "\n",
    "    def model(self, x, y):\n",
    "        # sample from prior\n",
    "        a = pyro.sample(\n",
    "            \"weight\", dist.Normal(self.alpha_h_loc, self.alpha_h_scale, validate_args=True).independent(1)\n",
    "        ).float()\n",
    "        b = pyro.sample(\n",
    "            \"bias\", dist.Normal(self.beta_h_loc, self.beta_h_scale, validate_args=True).independent(1)\n",
    "        ).float()\n",
    "\n",
    "        with pyro.iarange(\"data\", x.size(0)):\n",
    "#             import pdb; pdb.set_trace()\n",
    "            model_logits = (torch.matmul(x, a.permute(1, 0)) + b).squeeze()\n",
    "            \n",
    "            pyro.sample(\n",
    "                \"obs\", \n",
    "                dist.Bernoulli(logits=model_logits, validate_args=True),\n",
    "                obs=y.squeeze()\n",
    "            )\n",
    "            \n",
    "    def guide(self, x, y):\n",
    "        # register variational parameters with pyro\n",
    "        alpha_loc = pyro.param(\"alpha_loc\", torch.tensor(self.alpha_0))\n",
    "        alpha_scale = pyro.param(\"alpha_scale\", torch.tensor(self.alpha_0_scale),\n",
    "                                 constraint=constraints.positive)\n",
    "        beta_loc = pyro.param(\"beta_loc\", torch.tensor(self.beta_0))\n",
    "        beta_scale = pyro.param(\"beta_scale\", torch.tensor(self.beta_0_scale),\n",
    "                                constraint=constraints.positive)\n",
    "\n",
    "        pyro.sample(\n",
    "            \"weight\", dist.Normal(alpha_loc, alpha_scale, validate_args=True).independent(1)\n",
    "        )\n",
    "        pyro.sample(\n",
    "            \"bias\", dist.Normal(beta_loc, beta_scale, validate_args=True).independent(1)\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def guide_(self, x, y, N=100):\n",
    "        # register variational parameters with pyro\n",
    "        alpha_loc = pyro.param(\"alpha_loc\", torch.tensor(self.alpha_0))\n",
    "        alpha_scale = pyro.param(\"alpha_scale\", torch.tensor(self.alpha_0_scale),\n",
    "                                 constraint=constraints.positive)\n",
    "        beta_loc = pyro.param(\"beta_loc\", torch.tensor(self.beta_0))\n",
    "        beta_scale = pyro.param(\"beta_scale\", torch.tensor(self.beta_0_scale),\n",
    "                                constraint=constraints.positive)\n",
    "        w = []\n",
    "        b = []\n",
    "        for _ in range(N):\n",
    "            w.append(torch.tensor(pyro.sample(\n",
    "                \"weight\", dist.Normal(alpha_loc, alpha_scale, validate_args=True).independent(1)\n",
    "            )))\n",
    "            b.append(torch.tensor(pyro.sample(\n",
    "                \"bias\", dist.Normal(beta_loc, beta_scale, validate_args=True).independent(1)\n",
    "            )))\n",
    "#         import pdb;pdb.set_trace()\n",
    "        return torch.vstack(w), torch.vstack(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "optim = Adam({'lr': 0.01})\n",
    "\n",
    "num_epochs = 1000\n",
    "batch_size = 50\n",
    "\n",
    "N = X.shape[0]\n",
    "p = 2\n",
    "\n",
    "n_train = X_train.shape[0]\n",
    "example_indices = np.random.permutation(N)\n",
    "n_test = N - n_train\n",
    "test_iter = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogRegressionModel(p=p)\n",
    "\n",
    "svi = SVI(\n",
    "    lr_model.model, lr_model.guide, optim,\n",
    "    loss=Trace_ELBO()\n",
    ")\n",
    "\n",
    "\n",
    "lr_dataset = torch.utils.data.TensorDataset(torch.tensor(X[:,1:]).float(), torch.tensor(y.reshape(-1,1)).float())\n",
    "\n",
    "data_loader_train = DataLoader(\n",
    "    dataset=lr_dataset, batch_size=batch_size, pin_memory=False,\n",
    "    sampler=SubsetRandomSampler(example_indices[:n_train]),\n",
    ")\n",
    "    \n",
    "data_loader_test = DataLoader(\n",
    "    dataset=lr_dataset, batch_size=batch_size, pin_memory=False,\n",
    "    sampler=SubsetRandomSampler(example_indices[n_train:]),\n",
    ")\n",
    "\n",
    "train_elbo = []\n",
    "test_elbo = []\n",
    "for epoch in range(num_epochs):\n",
    "    total_epoch_loss_train = train(svi, data_loader_train, n_train)\n",
    "    train_elbo.append(-total_epoch_loss_train)\n",
    "\n",
    "    if epoch % test_iter == 0:\n",
    "        print(\"[epoch %03d]  average training loss: %.4f\" % (epoch, total_epoch_loss_train))\n",
    "        # report test diagnostics\n",
    "        total_epoch_loss_test = evaluate(svi, data_loader_test, n_test)\n",
    "        test_elbo.append(-total_epoch_loss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_llk(train_elbo, test_elbo, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, b = lr_model.guide_(X_train.float(), y_train.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2,ax3) = plt.subplots(1,3)\n",
    "\n",
    "# ax1.hist(Θ_1[:,0].detach().numpy())\n",
    "# ax2.hist(Θ_1[:,1].detach().numpy())\n",
    "# ax3.hist(Θ_1[:,2].detach().numpy())\n",
    "\n",
    "\n",
    "ax1.hist(b.detach().numpy(), color=\"red\")\n",
    "ax2.hist(W[:,0].detach().numpy(), color=\"red\")\n",
    "ax3.hist(W[:,1].detach().numpy(), color=\"red\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.mean(), W.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
