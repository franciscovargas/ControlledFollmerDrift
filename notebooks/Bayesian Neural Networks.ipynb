{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d0c30d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchsde\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "import functorch\n",
    "\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cfollmer.evaluation_utils import ECE\n",
    "import cfollmer.functional as functional\n",
    "from cfollmer.objectives import relative_entropy_control_cost, stl_control_cost\n",
    "from cfollmer.drifts import SimpleForwardNetBN, ScoreNetwork, ResNetScoreNetwork\n",
    "from cfollmer.sampler_utils import FollmerSDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deb5e7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7653c559",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.feature_extractor = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.AvgPool2d(kernel_size=2),\n",
    "            torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.AvgPool2d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=256, out_features=120),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(in_features=120, out_features=84),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(in_features=84, out_features=n_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        logits = self.classifier(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "057c26db",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = transforms.Compose([transforms.ToTensor(), transforms.RandomAffine(30)])\n",
    "\n",
    "MNIST_train = datasets.MNIST(\"../data/mnist/\", download=True, transform=ToTensor(), train=True)\n",
    "MNIST_test = datasets.MNIST(\"../data/mnist/\", download=True, transform=test_transforms, train=False)\n",
    "\n",
    "N_train = len(MNIST_train)\n",
    "N_test = len(MNIST_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe8fdabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet5(10).to(device)\n",
    "func_model, params = functorch.make_functional(model)\n",
    "size_list = functional.params_to_size_tuples(params)\n",
    "dim = functional.get_number_of_params(size_list)\n",
    "  \n",
    "sigma2 = 0.1\n",
    "\n",
    "def log_prior(params):\n",
    "    return -torch.sum(params**2) / (2 * sigma2)\n",
    "\n",
    "def log_likelihood(x, y, params):\n",
    "    preds = func_model(functional.get_params_from_array(params, size_list), x)\n",
    "    return -F.cross_entropy(preds, y, reduction=\"sum\")\n",
    "\n",
    "def log_likelihood_batch(x, y, params_batch):\n",
    "    func = lambda params: log_likelihood(x, y, params)\n",
    "    func = functorch.vmap(func)\n",
    "    return func(params_batch)\n",
    "\n",
    "def log_posterior(x, y, params):\n",
    "    return log_prior(params) + (N_train / x.shape[0]) * log_likelihood(x, y, params)\n",
    "\n",
    "def log_posterior_batch(x, y, params_batch):\n",
    "    func = lambda params: log_posterior(x, y, params)\n",
    "    func = functorch.vmap(func)\n",
    "    return func(params_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "224929a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(gamma, n_epochs, data_batch_size, param_batch_size, dt=0.05, stl=False):\n",
    "    sde = FollmerSDE(gamma, SimpleForwardNetBN(input_dim=dim, width=300)).to(device)\n",
    "#     sde = FollmerSDE(gamma, ResNetScoreNetwork(dim)).to(device)\n",
    "    optimizer = torch.optim.Adam(sde.parameters(), lr=1e-5)\n",
    "    \n",
    "    dataloader_train = DataLoader(MNIST_train, shuffle=True, batch_size=data_batch_size, num_workers=2)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for _ in range(n_epochs):\n",
    "        epoch_losses = []\n",
    "        for x, y in tqdm(iter(dataloader_train)):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            partial_log_p = lambda params_batch: log_posterior_batch(x, y, params_batch)\n",
    "            \n",
    "            if stl:\n",
    "                loss = stl_control_cost(sde, partial_log_p, param_batch_size=param_batch_size, dt=dt, device=device)\n",
    "            else:\n",
    "                loss = relative_entropy_control_cost(sde, partial_log_p, param_batch_size=param_batch_size, dt=dt, device=device)\n",
    "            loss.backward()\n",
    "\n",
    "            epoch_losses.append(loss.detach().cpu().numpy())\n",
    "            optimizer.step()\n",
    "            \n",
    "            if stl: # double check theres no references left\n",
    "                sde.drift_network_detatched.load_state_dict((sde.drift_network.state_dict()))\n",
    "            \n",
    "        #  Memory leaks somewhere with sdeint / param_T = param_trajectory[-1]\n",
    "        gc.collect()\n",
    "\n",
    "        losses.append(epoch_losses)\n",
    "    \n",
    "    losses = np.array(losses)\n",
    "    \n",
    "    return sde, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e5fef95",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.1**2\n",
    "n_epochs = 10\n",
    "data_batch_size = 32\n",
    "param_batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84016a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1875 [00:00<?, ?it/s]/local/scratch/home/fav25/hjb2/lib/python3.8/site-packages/torch/nn/functional.py:2378: UserWarning: There is a performance drop because we have not yet implemented the batching rule for aten::batch_norm. Please file us an issue on GitHub so that we can prioritize its implementation. (Triggered internally at  /tmp/pip-req-build-t07f5mpb/functorch/csrc/BatchedFallback.cpp:106.)\n",
      "  return torch.batch_norm(\n",
      "/local/scratch/home/fav25/hjb2/lib/python3.8/site-packages/torch/nn/functional.py:2942: UserWarning: There is a performance drop because we have not yet implemented the batching rule for aten::cross_entropy_loss. Please file us an issue on GitHub so that we can prioritize its implementation. (Triggered internally at  /tmp/pip-req-build-t07f5mpb/functorch/csrc/BatchedFallback.cpp:106.)\n",
      "  return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)\n",
      "100%|██████████| 1875/1875 [10:40<00:00,  2.93it/s]\n",
      "100%|██████████| 1875/1875 [10:51<00:00,  2.88it/s]\n",
      " 20%|██        | 376/1875 [02:12<08:49,  2.83it/s]"
     ]
    }
   ],
   "source": [
    "num_exp = 1\n",
    "\n",
    "for i in range(num_exp):\n",
    "    sde, losses = train(gamma, n_epochs, data_batch_size, param_batch_size, dt=0.05, stl=True)\n",
    "    torch.save(sde.state_dict(), \"weights/bnn/weights-stl-{:d}.pt\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdaa8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(sde.state_dict(), \"weights/bnn/weights-resnet-{:d}.pt\".format(i))\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5b979b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(param_samples):\n",
    "    dataloader_test = DataLoader(MNIST_test, shuffle=False, batch_size=data_batch_size, num_workers=2)\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_confidences = []\n",
    "    all_logps = []\n",
    "    \n",
    "    for x, y in tqdm(iter(dataloader_test)):\n",
    "        with torch.no_grad():\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            predict_func = lambda params : func_model(functional.get_params_from_array(params, size_list), x)\n",
    "            predict_func = functorch.vmap(predict_func)\n",
    "\n",
    "            out = F.softmax(predict_func(param_samples), dim=-1)\n",
    "            out = torch.mean(out, dim=0)\n",
    "            \n",
    "            confidences, predictions = torch.max(out, dim=1)\n",
    "\n",
    "            all_predictions.append(predictions)\n",
    "            all_confidences.append(confidences)\n",
    "            \n",
    "            all_logps.append(torch.mean(log_likelihood_batch(x, y, param_samples)))\n",
    "    \n",
    "    all_predictions = torch.hstack(all_predictions).cpu().numpy()\n",
    "    all_confidences = torch.hstack(all_confidences).cpu().numpy()\n",
    "    true_labels = MNIST_test.targets.numpy()\n",
    "    \n",
    "    accuracy = np.mean(all_predictions == true_labels)\n",
    "    ece = ECE(all_confidences, all_predictions, true_labels)\n",
    "    \n",
    "    logp = torch.sum(torch.stack(all_logps)) / N_test\n",
    "    logp = logp.cpu().numpy()\n",
    "    return accuracy, ece, logp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "365bd5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]/local/scratch/home/fav25/hjb2/lib/python3.8/site-packages/torch/nn/functional.py:2942: UserWarning: There is a performance drop because we have not yet implemented the batching rule for aten::cross_entropy_loss. Please file us an issue on GitHub so that we can prioritize its implementation. (Triggered internally at  /tmp/pip-req-build-t07f5mpb/functorch/csrc/BatchedFallback.cpp:106.)\n",
      "  return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)\n",
      "100%|██████████| 313/313 [00:02<00:00, 126.40it/s]\n"
     ]
    }
   ],
   "source": [
    "accuracies, eces, logps = [], [], []\n",
    "\n",
    "for i in range(num_exp):\n",
    "    sde = FollmerSDE(gamma, SimpleForwardNetBN(input_dim=dim, width=300)).to(device)\n",
    "#     sde = FollmerSDE(gamma, ResNetScoreNetwork(dim)).to(device)\n",
    "    sde.load_state_dict(torch.load(\"weights/bnn/weights-stl-{:d}.pt\".format(i)))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        param_samples = sde.sample(100, dt=0.005, device=device)\n",
    "    \n",
    "    accuracy, ece, logp = evaluate(param_samples)\n",
    "    \n",
    "    accuracies.append(accuracy)\n",
    "    eces.append(ece)\n",
    "    logps.append(logp)\n",
    "    \n",
    "accuracies = np.array(accuracies)\n",
    "eces = np.array(eces)\n",
    "logps = np.array(logps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec76f29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SBP_df = pd.DataFrame({\"Accuracy\": accuracies, \"ECE\": eces, \"log predictive\": logps})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48a86929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ECE</th>\n",
       "      <th>log predictive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9404</td>\n",
       "      <td>0.009862</td>\n",
       "      <td>-0.299734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy       ECE  log predictive\n",
       "0    0.9404  0.009862       -0.299734"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SBP_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4bee8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ECE</th>\n",
       "      <th>log predictive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.940020</td>\n",
       "      <td>0.005630</td>\n",
       "      <td>-0.290168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003786</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>0.021163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.003460</td>\n",
       "      <td>-0.319881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.938200</td>\n",
       "      <td>0.004022</td>\n",
       "      <td>-0.303128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.939400</td>\n",
       "      <td>0.004327</td>\n",
       "      <td>-0.285371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.943200</td>\n",
       "      <td>0.006186</td>\n",
       "      <td>-0.271571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.944300</td>\n",
       "      <td>0.010154</td>\n",
       "      <td>-0.270888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy       ECE  log predictive\n",
       "count  5.000000  5.000000        5.000000\n",
       "mean   0.940020  0.005630       -0.290168\n",
       "std    0.003786  0.002728        0.021163\n",
       "min    0.935000  0.003460       -0.319881\n",
       "25%    0.938200  0.004022       -0.303128\n",
       "50%    0.939400  0.004327       -0.285371\n",
       "75%    0.943200  0.006186       -0.271571\n",
       "max    0.944300  0.010154       -0.270888"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SBP_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c72591",
   "metadata": {},
   "source": [
    "SGLD from here onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5d716c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.enable_grad()\n",
    "def gradient(x, y, params):\n",
    "    params_ = params.clone().requires_grad_(True)\n",
    "    loss = log_posterior(x, y, params_)\n",
    "    grad, = torch.autograd.grad(loss, params_)\n",
    "    return loss.detach().cpu().numpy(), grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5349cc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_size(n):\n",
    "    return 1e-4 / (1 + n)**0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f371ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgld(n_epochs, data_batch_size):\n",
    "    dataloader_train = DataLoader(MNIST_train, shuffle=True, batch_size=data_batch_size, num_workers=2)\n",
    "    params = torch.cat([param.flatten() for param in model.parameters()]).detach()\n",
    "    losses = []\n",
    "    step = 0\n",
    "    for _ in range(n_epochs):\n",
    "        epoch_losses = []\n",
    "        for x, y in tqdm(iter(dataloader_train)):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            eps = step_size(step)\n",
    "            loss, grad = gradient(x, y, params)\n",
    "            params = params + 0.5 * eps * grad #+ np.sqrt(eps) * torch.randn_like(params)\n",
    "            step += 1\n",
    "            epoch_losses.append(loss)\n",
    "        \n",
    "        losses.append(epoch_losses)\n",
    "    \n",
    "    param_samples = []\n",
    "    \n",
    "    iterator = iter(dataloader_train)\n",
    "    for _ in range(100):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        eps = step_size(step)\n",
    "        loss, grad = gradient(x, y, params)\n",
    "        params = params + 0.5 * eps * grad + np.sqrt(eps) * torch.randn_like(params)\n",
    "        param_samples.append(params)\n",
    "        step += 1\n",
    "        \n",
    "    param_samples = torch.stack(param_samples)\n",
    "    losses = np.array(losses)\n",
    "    \n",
    "    return param_samples, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b434f51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 583.49it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 586.28it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 588.93it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 575.57it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 588.42it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 551.23it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 581.09it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 566.18it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 572.30it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 580.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 313/313 [00:01<00:00, 238.98it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 578.91it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 565.54it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 545.77it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 566.96it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 576.39it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 564.64it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 543.79it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 595.99it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 550.22it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 586.14it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 313/313 [00:01<00:00, 248.27it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 558.82it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 605.16it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 570.59it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 546.26it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 571.88it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 591.65it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 579.71it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 585.38it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 554.15it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 585.96it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 313/313 [00:01<00:00, 247.03it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 576.50it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 566.82it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 580.29it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 570.90it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 586.32it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 596.16it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 588.20it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 572.11it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 560.31it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 582.60it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 313/313 [00:01<00:00, 247.07it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 585.80it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 563.96it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 565.09it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 526.67it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 543.82it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 540.45it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 563.12it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 573.05it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 555.69it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:03<00:00, 576.36it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 313/313 [00:01<00:00, 251.57it/s]\n"
     ]
    }
   ],
   "source": [
    "accuracies, eces, logps = [], [], []\n",
    "\n",
    "for i in range(5):\n",
    "    param_samples, losses = sgld(n_epochs, data_batch_size)\n",
    "    \n",
    "    accuracy, ece, logp = evaluate(param_samples)\n",
    "    \n",
    "    accuracies.append(accuracy)\n",
    "    eces.append(ece)\n",
    "    logps.append(logp)\n",
    "    \n",
    "accuracies = np.array(accuracies)\n",
    "eces = np.array(eces)\n",
    "logps = np.array(logps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58574b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "SGLD_df = pd.DataFrame({\"Accuracy\": accuracies, \"ECE\": eces, \"log predictive\": logps})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89aa13f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ECE</th>\n",
       "      <th>log predictive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9370</td>\n",
       "      <td>0.009406</td>\n",
       "      <td>-0.201103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9370</td>\n",
       "      <td>0.011076</td>\n",
       "      <td>-0.198261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8647</td>\n",
       "      <td>0.019926</td>\n",
       "      <td>-0.436007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9313</td>\n",
       "      <td>0.012448</td>\n",
       "      <td>-0.221010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9261</td>\n",
       "      <td>0.019318</td>\n",
       "      <td>-0.243154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy       ECE  log predictive\n",
       "0    0.9370  0.009406       -0.201103\n",
       "1    0.9370  0.011076       -0.198261\n",
       "2    0.8647  0.019926       -0.436007\n",
       "3    0.9313  0.012448       -0.221010\n",
       "4    0.9261  0.019318       -0.243154"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGLD_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52789c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ECE</th>\n",
       "      <th>log predictive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.919220</td>\n",
       "      <td>0.014435</td>\n",
       "      <td>-0.259907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.030814</td>\n",
       "      <td>0.004861</td>\n",
       "      <td>0.100079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.864700</td>\n",
       "      <td>0.009406</td>\n",
       "      <td>-0.436007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.926100</td>\n",
       "      <td>0.011076</td>\n",
       "      <td>-0.243154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.931300</td>\n",
       "      <td>0.012448</td>\n",
       "      <td>-0.221010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.937000</td>\n",
       "      <td>0.019318</td>\n",
       "      <td>-0.201103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.937000</td>\n",
       "      <td>0.019926</td>\n",
       "      <td>-0.198261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy       ECE  log predictive\n",
       "count  5.000000  5.000000        5.000000\n",
       "mean   0.919220  0.014435       -0.259907\n",
       "std    0.030814  0.004861        0.100079\n",
       "min    0.864700  0.009406       -0.436007\n",
       "25%    0.926100  0.011076       -0.243154\n",
       "50%    0.931300  0.012448       -0.221010\n",
       "75%    0.937000  0.019318       -0.201103\n",
       "max    0.937000  0.019926       -0.198261"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGLD_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b55fb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(n_epochs, data_batch_size):\n",
    "    \n",
    "    dataloader_train = DataLoader(MNIST_train, shuffle=True, batch_size=data_batch_size, num_workers=2)\n",
    "    model = LeNet5(10).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "    losses = []\n",
    "\n",
    "    for i in range(n_epochs):\n",
    "        for x, y in tqdm(iter(dataloader_train)):\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            out = model(x)\n",
    "\n",
    "            l = F.cross_entropy(out, y, reduction=\"mean\")\n",
    "\n",
    "            l.backward()\n",
    "\n",
    "            losses.append(l.detach().cpu().numpy())\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "    losses = np.array(losses)\n",
    "    \n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ea33a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 715.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 694.22it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 703.74it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 691.18it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 692.61it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 703.72it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 689.86it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 701.62it/s]\n",
      " 84%|█████████████████████████████████████████████████▋         | 1580/1875 [00:02<00:00, 754.53it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f49ededb700>\n",
      "Exception ignored in: Traceback (most recent call last):\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f49ededb700>  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "\n",
      "    Traceback (most recent call last):\n",
      "self._shutdown_workers()  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "\n",
      "      File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "self._shutdown_workers()    \n",
      "if w.is_alive():\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "        if w.is_alive():assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "AssertionError:     can only test a child processassert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "AssertionError: can only test a child process\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 690.41it/s]\n",
      " 51%|██████████████████████████████▌                             | 957/1875 [00:01<00:01, 744.47it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f49ededb700>Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f49ededb700>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()    \n",
      "self._shutdown_workers()  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():    \n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "if w.is_alive():\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "    AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process': \n",
      "can only test a child processAssertionError\n",
      ": can only test a child process\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 681.47it/s]\n",
      "  0%|                                                                        | 0/313 [00:00<?, ?it/s]/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/nn/functional.py:2948: UserWarning: There is a performance drop because we have not yet implemented the batching rule for aten::cross_entropy_loss. Please file us an issue on GitHub so that we can prioritize its implementation. (Triggered internally at  /tmp/pip-req-build-b9xxrrfi/functorch/csrc/BatchedFallback.cpp:106.)\n",
      "  return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)\n",
      "100%|█████████████████████████████████████████████████████████████| 313/313 [00:01<00:00, 258.50it/s]\n",
      " 85%|█████████████████████████████████████████████████▉         | 1587/1875 [00:02<00:00, 731.86it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f49ededb700>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()Exception ignored in: \n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f49ededb700>\n",
      "    Traceback (most recent call last):\n",
      "if w.is_alive():  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "        self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "AssertionError    : if w.is_alive():can only test a child process\n",
      "\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 653.39it/s]\n",
      " 53%|███████████████████████████████▋                            | 992/1875 [00:01<00:01, 764.66it/s]Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f49ededb700><function _MultiProcessingDataLoaderIter.__del__ at 0x7f49ededb700>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "        self._shutdown_workers()self._shutdown_workers()\n",
      "\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "        if w.is_alive():if w.is_alive():\n",
      "\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "        assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "AssertionErrorAssertionError: : can only test a child processcan only test a child process\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 705.43it/s]\n",
      " 32%|███████████████████                                         | 595/1875 [00:00<00:01, 755.58it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f49ededb700>\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in:   File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f49ededb700>\n",
      "    Traceback (most recent call last):\n",
      "self._shutdown_workers()  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    self._shutdown_workers()    \n",
      "if w.is_alive():  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "        if w.is_alive():\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "    AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process': \n",
      "can only test a child processAssertionError\n",
      ": can only test a child process\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 698.87it/s]\n",
      "  0%|                                                                       | 0/1875 [00:00<?, ?it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f49ededb700>Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f49ededb700>Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()    \n",
      "self._shutdown_workers()  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "  2%|█                                                            | 31/1875 [00:00<00:06, 275.74it/s]\n",
      "\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "        assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "AssertionErrorAssertionError: : can only test a child processcan only test a child process\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 698.93it/s]\n",
      "  0%|                                                                       | 0/1875 [00:00<?, ?it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f49ededb700>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f49ededb700>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  0%|▏                                                              | 4/1875 [00:00<00:54, 34.54it/s]  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 659.24it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 691.05it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 687.40it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 691.34it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 693.90it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 676.06it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 313/313 [00:01<00:00, 248.41it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 726.11it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 709.37it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 700.13it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 705.33it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 709.89it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 705.18it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 707.90it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 698.45it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 711.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 708.31it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 313/313 [00:01<00:00, 255.13it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 694.96it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 706.54it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 692.91it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 692.33it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 692.93it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 684.29it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 702.83it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 683.00it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 694.22it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 693.33it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 313/313 [00:01<00:00, 256.52it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 666.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 702.55it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 703.01it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 677.25it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 681.66it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 673.31it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 722.37it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 731.75it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 697.77it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 721.28it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 313/313 [00:01<00:00, 253.57it/s]\n"
     ]
    }
   ],
   "source": [
    "accuracies, eces, logps = [], [], []\n",
    "\n",
    "for i in range(5):\n",
    "    model, losses = sgd(n_epochs, data_batch_size)\n",
    "    params = model.parameters()\n",
    "    params = torch.cat([param.flatten() for param in params]).detach()\n",
    "    params = params.view(1, -1)\n",
    "    accuracy, ece, logp = evaluate(params)\n",
    "    \n",
    "    accuracies.append(accuracy)\n",
    "    eces.append(ece)\n",
    "    logps.append(logp)\n",
    "    \n",
    "accuracies = np.array(accuracies)\n",
    "eces = np.array(eces)\n",
    "logps = np.array(logps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84b2cf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD_df = pd.DataFrame({\"Accuracy\": accuracies, \"ECE\": eces, \"log predictive\": logps})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98de7a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ECE</th>\n",
       "      <th>log predictive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9115</td>\n",
       "      <td>0.009907</td>\n",
       "      <td>-0.271943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9166</td>\n",
       "      <td>0.008780</td>\n",
       "      <td>-0.269324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9174</td>\n",
       "      <td>0.009571</td>\n",
       "      <td>-0.262576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9079</td>\n",
       "      <td>0.007665</td>\n",
       "      <td>-0.290798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9102</td>\n",
       "      <td>0.010044</td>\n",
       "      <td>-0.273837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy       ECE  log predictive\n",
       "0    0.9115  0.009907       -0.271943\n",
       "1    0.9166  0.008780       -0.269324\n",
       "2    0.9174  0.009571       -0.262576\n",
       "3    0.9079  0.007665       -0.290798\n",
       "4    0.9102  0.010044       -0.273837"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70c6d003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ECE</th>\n",
       "      <th>log predictive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.912720</td>\n",
       "      <td>0.009193</td>\n",
       "      <td>-0.273696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.004124</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>0.010468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.907900</td>\n",
       "      <td>0.007665</td>\n",
       "      <td>-0.290798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.910200</td>\n",
       "      <td>0.008780</td>\n",
       "      <td>-0.273837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.911500</td>\n",
       "      <td>0.009571</td>\n",
       "      <td>-0.271943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.916600</td>\n",
       "      <td>0.009907</td>\n",
       "      <td>-0.269324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.917400</td>\n",
       "      <td>0.010044</td>\n",
       "      <td>-0.262576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy       ECE  log predictive\n",
       "count  5.000000  5.000000        5.000000\n",
       "mean   0.912720  0.009193       -0.273696\n",
       "std    0.004124  0.000985        0.010468\n",
       "min    0.907900  0.007665       -0.290798\n",
       "25%    0.910200  0.008780       -0.273837\n",
       "50%    0.911500  0.009571       -0.271943\n",
       "75%    0.916600  0.009907       -0.269324\n",
       "max    0.917400  0.010044       -0.262576"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD_df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
