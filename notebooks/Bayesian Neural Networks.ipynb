{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d0c30d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchsde\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "import functorch\n",
    "\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cfollmer.evaluation_utils import ECE\n",
    "import cfollmer.functional as functional\n",
    "from cfollmer.objectives import relative_entropy_control_cost, stl_control_cost\n",
    "from cfollmer.drifts import SimpleForwardNetBN, ScoreNetwork, ResNetScoreNetwork\n",
    "from cfollmer.sampler_utils import FollmerSDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deb5e7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7653c559",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.feature_extractor = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.AvgPool2d(kernel_size=2),\n",
    "            torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.AvgPool2d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=256, out_features=120),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(in_features=120, out_features=84),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(in_features=84, out_features=n_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        logits = self.classifier(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "057c26db",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = transforms.Compose([transforms.ToTensor(), transforms.RandomAffine(30)])\n",
    "\n",
    "MNIST_train = datasets.MNIST(\"../data/mnist/\", download=True, transform=ToTensor(), train=True)\n",
    "MNIST_test = datasets.MNIST(\"../data/mnist/\", download=True, transform=test_transforms, train=False)\n",
    "\n",
    "N_train = len(MNIST_train)\n",
    "N_test = len(MNIST_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe8fdabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet5(10).to(device)\n",
    "func_model, params = functorch.make_functional(model)\n",
    "size_list = functional.params_to_size_tuples(params)\n",
    "dim = functional.get_number_of_params(size_list)\n",
    "  \n",
    "sigma2 = 1\n",
    "\n",
    "def log_prior(params):\n",
    "    return -torch.sum(params**2) / (2 * sigma2)\n",
    "\n",
    "def log_likelihood(x, y, params):\n",
    "    preds = func_model(functional.get_params_from_array(params, size_list), x)\n",
    "    return -F.cross_entropy(preds, y, reduction=\"sum\")\n",
    "\n",
    "def log_likelihood_batch(x, y, params_batch):\n",
    "    func = lambda params: log_likelihood(x, y, params)\n",
    "    func = functorch.vmap(func)\n",
    "    return func(params_batch)\n",
    "\n",
    "def log_posterior(x, y, params):\n",
    "    return log_prior(params) + (N_train / x.shape[0]) * log_likelihood(x, y, params)\n",
    "\n",
    "def log_posterior_batch(x, y, params_batch):\n",
    "    func = lambda params: log_posterior(x, y, params)\n",
    "    func = functorch.vmap(func)\n",
    "    return func(params_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "224929a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(gamma, n_epochs, data_batch_size, param_batch_size, dt=0.05, stl=False):\n",
    "#     sde = FollmerSDE(gamma, SimpleForwardNetBN(input_dim=dim, width=300)).to(device)\n",
    "    sde = FollmerSDE(gamma, ResNetScoreNetwork(dim)).to(device)\n",
    "    optimizer = torch.optim.Adam(sde.parameters(), lr=1e-5)\n",
    "    \n",
    "    dataloader_train = DataLoader(MNIST_train, shuffle=True, batch_size=data_batch_size, num_workers=2)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for _ in range(n_epochs):\n",
    "        epoch_losses = []\n",
    "        for x, y in tqdm(iter(dataloader_train)):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            partial_log_p = lambda params_batch: log_posterior_batch(x, y, params_batch)\n",
    "            \n",
    "            if stl:\n",
    "                loss = stl_control_cost(sde, partial_log_p, param_batch_size=param_batch_size, dt=dt, device=device)\n",
    "            else:\n",
    "                loss = relative_entropy_control_cost(sde, partial_log_p, param_batch_size=param_batch_size, dt=dt, device=device)\n",
    "            loss.backward()\n",
    "\n",
    "            epoch_losses.append(loss.detach().cpu().numpy())\n",
    "            optimizer.step()\n",
    "            \n",
    "            if stl: # double check theres no references left\n",
    "                sde.drift_network_detatched.load_state_dict((sde.drift_network.state_dict()))\n",
    "            \n",
    "        #  Memory leaks somewhere with sdeint / param_T = param_trajectory[-1]\n",
    "        gc.collect()\n",
    "\n",
    "        losses.append(epoch_losses)\n",
    "    \n",
    "    losses = np.array(losses)\n",
    "    \n",
    "    return sde, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e5fef95",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.2**2\n",
    "# gamma = 1**2\n",
    "n_epochs = 10\n",
    "data_batch_size = 32\n",
    "param_batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e84016a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1875 [00:00<?, ?it/s]/local/scratch/home/fav25/hjb2/lib/python3.8/site-packages/torch/nn/functional.py:2942: UserWarning: There is a performance drop because we have not yet implemented the batching rule for aten::cross_entropy_loss. Please file us an issue on GitHub so that we can prioritize its implementation. (Triggered internally at  /tmp/pip-req-build-t07f5mpb/functorch/csrc/BatchedFallback.cpp:106.)\n",
      "  return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)\n",
      "100%|██████████| 1875/1875 [04:02<00:00,  7.72it/s]\n",
      "100%|██████████| 1875/1875 [04:16<00:00,  7.30it/s]\n",
      "100%|██████████| 1875/1875 [04:05<00:00,  7.63it/s]\n",
      "100%|██████████| 1875/1875 [04:08<00:00,  7.55it/s]\n",
      "100%|██████████| 1875/1875 [04:03<00:00,  7.70it/s]\n",
      "100%|██████████| 1875/1875 [04:02<00:00,  7.73it/s]\n",
      "100%|██████████| 1875/1875 [04:03<00:00,  7.68it/s]\n",
      "100%|██████████| 1875/1875 [04:02<00:00,  7.73it/s]\n",
      "100%|██████████| 1875/1875 [04:03<00:00,  7.71it/s]\n",
      "100%|██████████| 1875/1875 [04:01<00:00,  7.75it/s]\n",
      "100%|██████████| 1875/1875 [04:02<00:00,  7.73it/s]\n",
      "100%|██████████| 1875/1875 [04:03<00:00,  7.71it/s]\n",
      "100%|██████████| 1875/1875 [04:03<00:00,  7.71it/s]\n",
      "100%|██████████| 1875/1875 [04:03<00:00,  7.71it/s]\n",
      "100%|██████████| 1875/1875 [04:02<00:00,  7.72it/s]\n",
      "100%|██████████| 1875/1875 [04:04<00:00,  7.67it/s]\n",
      "100%|██████████| 1875/1875 [04:04<00:00,  7.66it/s]\n",
      "100%|██████████| 1875/1875 [04:04<00:00,  7.67it/s]\n",
      "100%|██████████| 1875/1875 [04:04<00:00,  7.66it/s]\n",
      "100%|██████████| 1875/1875 [04:04<00:00,  7.68it/s]\n",
      "100%|██████████| 1875/1875 [04:02<00:00,  7.72it/s]\n",
      "100%|██████████| 1875/1875 [04:04<00:00,  7.68it/s]\n",
      "100%|██████████| 1875/1875 [04:04<00:00,  7.67it/s]\n",
      "100%|██████████| 1875/1875 [04:04<00:00,  7.66it/s]\n",
      "100%|██████████| 1875/1875 [04:03<00:00,  7.70it/s]\n",
      "100%|██████████| 1875/1875 [04:03<00:00,  7.70it/s]\n",
      "100%|██████████| 1875/1875 [04:04<00:00,  7.68it/s]\n",
      "100%|██████████| 1875/1875 [04:04<00:00,  7.68it/s]\n",
      "100%|██████████| 1875/1875 [04:04<00:00,  7.68it/s]\n",
      "100%|██████████| 1875/1875 [04:04<00:00,  7.65it/s]\n"
     ]
    }
   ],
   "source": [
    "num_exp = 3\n",
    "\n",
    "for i in range(num_exp):\n",
    "    sde, losses = train(gamma, n_epochs, data_batch_size, param_batch_size, dt=0.05, stl=False)\n",
    "    torch.save(sde.state_dict(), \"weights/bnn/weights-resnet-sigma1-{:d}.pt\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fdaa8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# torch.save(sde.state_dict(), \"weights/bnn/weights-resnet-{:d}.pt\".format(i))\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb5b979b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(param_samples):\n",
    "    dataloader_test = DataLoader(MNIST_test, shuffle=False, batch_size=data_batch_size, num_workers=2)\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_confidences = []\n",
    "    all_logps = []\n",
    "    \n",
    "    for x, y in tqdm(iter(dataloader_test)):\n",
    "        with torch.no_grad():\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            predict_func = lambda params : func_model(functional.get_params_from_array(params, size_list), x)\n",
    "            predict_func = functorch.vmap(predict_func)\n",
    "\n",
    "            out = F.softmax(predict_func(param_samples), dim=-1)\n",
    "            out = torch.mean(out, dim=0)\n",
    "            \n",
    "            confidences, predictions = torch.max(out, dim=1)\n",
    "\n",
    "            all_predictions.append(predictions)\n",
    "            all_confidences.append(confidences)\n",
    "            \n",
    "            all_logps.append(torch.mean(log_likelihood_batch(x, y, param_samples)))\n",
    "    \n",
    "    all_predictions = torch.hstack(all_predictions).cpu().numpy()\n",
    "    all_confidences = torch.hstack(all_confidences).cpu().numpy()\n",
    "    true_labels = MNIST_test.targets.numpy()\n",
    "    \n",
    "    accuracy = np.mean(all_predictions == true_labels)\n",
    "    ece = ECE(all_confidences, all_predictions, true_labels)\n",
    "    \n",
    "    logp = torch.sum(torch.stack(all_logps)) / N_test\n",
    "    logp = logp.cpu().numpy()\n",
    "    return accuracy, ece, logp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "365bd5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 123.58it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 123.86it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 126.36it/s]\n"
     ]
    }
   ],
   "source": [
    "accuracies, eces, logps = [], [], []\n",
    "\n",
    "for i in range(num_exp):\n",
    "#     sde = FollmerSDE(gamma, SimpleForwardNetBN(input_dim=dim, width=300)).to(device)\n",
    "    sde = FollmerSDE(gamma, ResNetScoreNetwork(dim)).to(device)\n",
    "    sde.load_state_dict(torch.load(\"weights/bnn/weights-resnet-sigma1-{:d}.pt\".format(i)))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        param_samples = sde.sample(100, dt=0.005, device=device)\n",
    "    \n",
    "    accuracy, ece, logp = evaluate(param_samples)\n",
    "    \n",
    "    accuracies.append(accuracy)\n",
    "    eces.append(ece)\n",
    "    logps.append(logp)\n",
    "    \n",
    "accuracies = np.array(accuracies)\n",
    "eces = np.array(eces)\n",
    "logps = np.array(logps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec76f29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SBP_df = pd.DataFrame({\"Accuracy\": accuracies, \"ECE\": eces, \"log predictive\": logps})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3d97fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48a86929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ECE</th>\n",
       "      <th>log predictive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9484</td>\n",
       "      <td>0.004773</td>\n",
       "      <td>-0.386982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9428</td>\n",
       "      <td>0.005549</td>\n",
       "      <td>-0.436452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9524</td>\n",
       "      <td>0.006941</td>\n",
       "      <td>-0.354880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy       ECE  log predictive\n",
       "0    0.9484  0.004773       -0.386982\n",
       "1    0.9428  0.005549       -0.436452\n",
       "2    0.9524  0.006941       -0.354880"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SBP_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4bee8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ECE</th>\n",
       "      <th>log predictive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.947867</td>\n",
       "      <td>0.005754</td>\n",
       "      <td>-0.392771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.004822</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>0.041093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.942800</td>\n",
       "      <td>0.004773</td>\n",
       "      <td>-0.436452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.945600</td>\n",
       "      <td>0.005161</td>\n",
       "      <td>-0.411717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.948400</td>\n",
       "      <td>0.005549</td>\n",
       "      <td>-0.386982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.950400</td>\n",
       "      <td>0.006245</td>\n",
       "      <td>-0.370931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.952400</td>\n",
       "      <td>0.006941</td>\n",
       "      <td>-0.354880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy       ECE  log predictive\n",
       "count  3.000000  3.000000        3.000000\n",
       "mean   0.947867  0.005754       -0.392771\n",
       "std    0.004822  0.001099        0.041093\n",
       "min    0.942800  0.004773       -0.436452\n",
       "25%    0.945600  0.005161       -0.411717\n",
       "50%    0.948400  0.005549       -0.386982\n",
       "75%    0.950400  0.006245       -0.370931\n",
       "max    0.952400  0.006941       -0.354880"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SBP_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c72591",
   "metadata": {},
   "source": [
    "SGLD from here onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5d716c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.enable_grad()\n",
    "def gradient(x, y, params):\n",
    "    params_ = params.clone().requires_grad_(True)\n",
    "    loss = log_posterior(x, y, params_)\n",
    "    grad, = torch.autograd.grad(loss, params_)\n",
    "    return loss.detach().cpu().numpy(), grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5349cc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_size(n):\n",
    "    return 1e-4 / (1 + n)**0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f371ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgld(n_epochs, data_batch_size):\n",
    "    dataloader_train = DataLoader(MNIST_train, shuffle=True, batch_size=data_batch_size, num_workers=2)\n",
    "    params = torch.cat([param.flatten() for param in model.parameters()]).detach()\n",
    "    losses = []\n",
    "    step = 0\n",
    "    for _ in range(n_epochs):\n",
    "        epoch_losses = []\n",
    "        for x, y in tqdm(iter(dataloader_train)):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            eps = step_size(step)\n",
    "            loss, grad = gradient(x, y, params)\n",
    "            params = params + 0.5 * eps * grad #+ np.sqrt(eps) * torch.randn_like(params)\n",
    "            step += 1\n",
    "            epoch_losses.append(loss)\n",
    "        \n",
    "        losses.append(epoch_losses)\n",
    "    \n",
    "    param_samples = []\n",
    "    \n",
    "    iterator = iter(dataloader_train)\n",
    "    for _ in range(100):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        eps = step_size(step)\n",
    "        loss, grad = gradient(x, y, params)\n",
    "        params = params + 0.5 * eps * grad + np.sqrt(eps) * torch.randn_like(params)\n",
    "        param_samples.append(params)\n",
    "        step += 1\n",
    "        \n",
    "    param_samples = torch.stack(param_samples)\n",
    "    losses = np.array(losses)\n",
    "    \n",
    "    return param_samples, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b434f51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:05<00:00, 341.45it/s]\n",
      "100%|██████████| 1875/1875 [00:06<00:00, 306.48it/s]\n",
      "100%|██████████| 1875/1875 [00:05<00:00, 315.63it/s]\n",
      "100%|██████████| 1875/1875 [00:06<00:00, 306.48it/s]\n",
      "100%|██████████| 1875/1875 [00:06<00:00, 309.51it/s]\n",
      "100%|██████████| 1875/1875 [00:06<00:00, 307.62it/s]\n",
      "100%|██████████| 1875/1875 [00:06<00:00, 304.97it/s]\n",
      "100%|██████████| 1875/1875 [00:06<00:00, 302.22it/s]\n",
      "100%|██████████| 1875/1875 [00:06<00:00, 304.57it/s]\n",
      "100%|██████████| 1875/1875 [00:06<00:00, 301.56it/s]\n",
      "  0%|          | 0/313 [00:00<?, ?it/s]/local/scratch/home/fav25/hjb2/lib/python3.8/site-packages/torch/nn/functional.py:2942: UserWarning: There is a performance drop because we have not yet implemented the batching rule for aten::cross_entropy_loss. Please file us an issue on GitHub so that we can prioritize its implementation. (Triggered internally at  /tmp/pip-req-build-t07f5mpb/functorch/csrc/BatchedFallback.cpp:106.)\n",
      "  return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)\n",
      "100%|██████████| 313/313 [00:02<00:00, 127.88it/s]\n",
      "100%|██████████| 1875/1875 [00:05<00:00, 313.93it/s]\n",
      "100%|██████████| 1875/1875 [00:06<00:00, 311.23it/s]\n",
      "100%|██████████| 1875/1875 [00:06<00:00, 294.66it/s]\n",
      "100%|██████████| 1875/1875 [00:05<00:00, 314.42it/s]\n",
      "100%|██████████| 1875/1875 [00:06<00:00, 303.36it/s]\n",
      "100%|██████████| 1875/1875 [00:06<00:00, 308.37it/s]\n",
      "100%|██████████| 1875/1875 [00:05<00:00, 336.74it/s]\n",
      "100%|██████████| 1875/1875 [00:05<00:00, 335.60it/s]\n",
      "100%|██████████| 1875/1875 [00:05<00:00, 320.30it/s]\n",
      "100%|██████████| 1875/1875 [00:06<00:00, 301.37it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 125.32it/s]\n",
      "100%|██████████| 1875/1875 [00:05<00:00, 315.92it/s]\n",
      "100%|██████████| 1875/1875 [00:06<00:00, 311.22it/s]\n",
      "100%|██████████| 1875/1875 [00:06<00:00, 285.41it/s]\n",
      "100%|██████████| 1875/1875 [00:05<00:00, 315.99it/s]\n",
      "100%|██████████| 1875/1875 [00:06<00:00, 290.56it/s]\n",
      "100%|██████████| 1875/1875 [00:06<00:00, 299.20it/s]\n",
      "100%|██████████| 1875/1875 [00:06<00:00, 300.79it/s]\n",
      "100%|██████████| 1875/1875 [00:06<00:00, 311.94it/s]\n",
      "100%|██████████| 1875/1875 [00:05<00:00, 321.78it/s]\n",
      "100%|██████████| 1875/1875 [00:05<00:00, 330.38it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 127.51it/s]\n",
      "100%|██████████| 1875/1875 [00:05<00:00, 333.05it/s]\n",
      "100%|██████████| 1875/1875 [00:05<00:00, 334.20it/s]\n",
      "100%|██████████| 1875/1875 [00:06<00:00, 302.31it/s]\n",
      "100%|██████████| 1875/1875 [00:05<00:00, 323.90it/s]\n",
      "100%|██████████| 1875/1875 [00:05<00:00, 317.95it/s]\n",
      "100%|██████████| 1875/1875 [00:05<00:00, 337.55it/s]\n",
      "100%|██████████| 1875/1875 [00:05<00:00, 339.96it/s]\n",
      "100%|██████████| 1875/1875 [00:05<00:00, 337.98it/s]\n",
      "100%|██████████| 1875/1875 [00:05<00:00, 337.83it/s]\n",
      "100%|██████████| 1875/1875 [00:05<00:00, 317.52it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 125.64it/s]\n",
      "100%|██████████| 1875/1875 [00:05<00:00, 318.70it/s]\n",
      "100%|██████████| 1875/1875 [00:06<00:00, 306.29it/s]\n",
      "100%|██████████| 1875/1875 [00:05<00:00, 346.47it/s]\n",
      "100%|██████████| 1875/1875 [00:05<00:00, 336.98it/s]\n",
      "100%|██████████| 1875/1875 [00:05<00:00, 340.86it/s]\n",
      "100%|██████████| 1875/1875 [00:05<00:00, 349.84it/s]\n",
      "100%|██████████| 1875/1875 [00:05<00:00, 337.69it/s]\n",
      "100%|██████████| 1875/1875 [00:05<00:00, 348.98it/s]\n",
      "100%|██████████| 1875/1875 [00:05<00:00, 342.52it/s]\n",
      "100%|██████████| 1875/1875 [00:06<00:00, 308.32it/s]\n",
      "100%|██████████| 313/313 [00:02<00:00, 126.43it/s]\n"
     ]
    }
   ],
   "source": [
    "accuracies, eces, logps = [], [], []\n",
    "\n",
    "for i in range(5):\n",
    "    param_samples, losses = sgld(n_epochs, data_batch_size)\n",
    "    \n",
    "    accuracy, ece, logp = evaluate(param_samples)\n",
    "    \n",
    "    accuracies.append(accuracy)\n",
    "    eces.append(ece)\n",
    "    logps.append(logp)\n",
    "    \n",
    "accuracies = np.array(accuracies)\n",
    "eces = np.array(eces)\n",
    "logps = np.array(logps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58574b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "SGLD_df = pd.DataFrame({\"Accuracy\": accuracies, \"ECE\": eces, \"log predictive\": logps})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89aa13f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ECE</th>\n",
       "      <th>log predictive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0892</td>\n",
       "      <td>0.093154</td>\n",
       "      <td>-2.407456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9277</td>\n",
       "      <td>0.014658</td>\n",
       "      <td>-0.221100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9332</td>\n",
       "      <td>0.017694</td>\n",
       "      <td>-0.230874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0980</td>\n",
       "      <td>0.084175</td>\n",
       "      <td>-2.425903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9365</td>\n",
       "      <td>0.013428</td>\n",
       "      <td>-0.211999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy       ECE  log predictive\n",
       "0    0.0892  0.093154       -2.407456\n",
       "1    0.9277  0.014658       -0.221100\n",
       "2    0.9332  0.017694       -0.230874\n",
       "3    0.0980  0.084175       -2.425903\n",
       "4    0.9365  0.013428       -0.211999"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGLD_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "52789c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ECE</th>\n",
       "      <th>log predictive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.596920</td>\n",
       "      <td>0.044622</td>\n",
       "      <td>-1.099466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.459487</td>\n",
       "      <td>0.040360</td>\n",
       "      <td>1.202482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.089200</td>\n",
       "      <td>0.013428</td>\n",
       "      <td>-2.425903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.098000</td>\n",
       "      <td>0.014658</td>\n",
       "      <td>-2.407456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.927700</td>\n",
       "      <td>0.017694</td>\n",
       "      <td>-0.230874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.933200</td>\n",
       "      <td>0.084175</td>\n",
       "      <td>-0.221100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.936500</td>\n",
       "      <td>0.093154</td>\n",
       "      <td>-0.211999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy       ECE  log predictive\n",
       "count  5.000000  5.000000        5.000000\n",
       "mean   0.596920  0.044622       -1.099466\n",
       "std    0.459487  0.040360        1.202482\n",
       "min    0.089200  0.013428       -2.425903\n",
       "25%    0.098000  0.014658       -2.407456\n",
       "50%    0.927700  0.017694       -0.230874\n",
       "75%    0.933200  0.084175       -0.221100\n",
       "max    0.936500  0.093154       -0.211999"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGLD_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b55fb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(n_epochs, data_batch_size):\n",
    "    \n",
    "    dataloader_train = DataLoader(MNIST_train, shuffle=True, batch_size=data_batch_size, num_workers=2)\n",
    "    model = LeNet5(10).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "    losses = []\n",
    "\n",
    "    for i in range(n_epochs):\n",
    "        for x, y in tqdm(iter(dataloader_train)):\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            out = model(x)\n",
    "\n",
    "            l = F.cross_entropy(out, y, reduction=\"mean\")\n",
    "\n",
    "            l.backward()\n",
    "\n",
    "            losses.append(l.detach().cpu().numpy())\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "    losses = np.array(losses)\n",
    "    \n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ea33a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 715.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 694.22it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 703.74it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 691.18it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 692.61it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 703.72it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 689.86it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 701.62it/s]\n",
      " 84%|█████████████████████████████████████████████████▋         | 1580/1875 [00:02<00:00, 754.53it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f49ededb700>\n",
      "Exception ignored in: Traceback (most recent call last):\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f49ededb700>  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "\n",
      "    Traceback (most recent call last):\n",
      "self._shutdown_workers()  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "\n",
      "      File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "self._shutdown_workers()    \n",
      "if w.is_alive():\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "        if w.is_alive():assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "AssertionError:     can only test a child processassert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "AssertionError: can only test a child process\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 690.41it/s]\n",
      " 51%|██████████████████████████████▌                             | 957/1875 [00:01<00:01, 744.47it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f49ededb700>Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f49ededb700>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()    \n",
      "self._shutdown_workers()  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():    \n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "if w.is_alive():\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "    AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process': \n",
      "can only test a child processAssertionError\n",
      ": can only test a child process\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 681.47it/s]\n",
      "  0%|                                                                        | 0/313 [00:00<?, ?it/s]/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/nn/functional.py:2948: UserWarning: There is a performance drop because we have not yet implemented the batching rule for aten::cross_entropy_loss. Please file us an issue on GitHub so that we can prioritize its implementation. (Triggered internally at  /tmp/pip-req-build-b9xxrrfi/functorch/csrc/BatchedFallback.cpp:106.)\n",
      "  return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)\n",
      "100%|█████████████████████████████████████████████████████████████| 313/313 [00:01<00:00, 258.50it/s]\n",
      " 85%|█████████████████████████████████████████████████▉         | 1587/1875 [00:02<00:00, 731.86it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f49ededb700>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()Exception ignored in: \n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f49ededb700>\n",
      "    Traceback (most recent call last):\n",
      "if w.is_alive():  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "        self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "AssertionError    : if w.is_alive():can only test a child process\n",
      "\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 653.39it/s]\n",
      " 53%|███████████████████████████████▋                            | 992/1875 [00:01<00:01, 764.66it/s]Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f49ededb700><function _MultiProcessingDataLoaderIter.__del__ at 0x7f49ededb700>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "        self._shutdown_workers()self._shutdown_workers()\n",
      "\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "        if w.is_alive():if w.is_alive():\n",
      "\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "        assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "AssertionErrorAssertionError: : can only test a child processcan only test a child process\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 705.43it/s]\n",
      " 32%|███████████████████                                         | 595/1875 [00:00<00:01, 755.58it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f49ededb700>\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in:   File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f49ededb700>\n",
      "    Traceback (most recent call last):\n",
      "self._shutdown_workers()  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    self._shutdown_workers()    \n",
      "if w.is_alive():  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "        if w.is_alive():\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "    AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process': \n",
      "can only test a child processAssertionError\n",
      ": can only test a child process\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 698.87it/s]\n",
      "  0%|                                                                       | 0/1875 [00:00<?, ?it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f49ededb700>Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f49ededb700>Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()    \n",
      "self._shutdown_workers()  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "  2%|█                                                            | 31/1875 [00:00<00:06, 275.74it/s]\n",
      "\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "        assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "AssertionErrorAssertionError: : can only test a child processcan only test a child process\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 698.93it/s]\n",
      "  0%|                                                                       | 0/1875 [00:00<?, ?it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f49ededb700>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f49ededb700>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  0%|▏                                                              | 4/1875 [00:00<00:54, 34.54it/s]  File \"/home/ao464@ad.eng.cam.ac.uk/repos/ControlledFollmerDrift/env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 659.24it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 691.05it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 687.40it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 691.34it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 693.90it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 676.06it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 313/313 [00:01<00:00, 248.41it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 726.11it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 709.37it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 700.13it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 705.33it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 709.89it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 705.18it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 707.90it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 698.45it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 711.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 708.31it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 313/313 [00:01<00:00, 255.13it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 694.96it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 706.54it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 692.91it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 692.33it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 692.93it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 684.29it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 702.83it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 683.00it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 694.22it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 693.33it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 313/313 [00:01<00:00, 256.52it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 666.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 702.55it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 703.01it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 677.25it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 681.66it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 673.31it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 722.37it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 731.75it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 697.77it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 1875/1875 [00:02<00:00, 721.28it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 313/313 [00:01<00:00, 253.57it/s]\n"
     ]
    }
   ],
   "source": [
    "accuracies, eces, logps = [], [], []\n",
    "\n",
    "for i in range(5):\n",
    "    model, losses = sgd(n_epochs, data_batch_size)\n",
    "    params = model.parameters()\n",
    "    params = torch.cat([param.flatten() for param in params]).detach()\n",
    "    params = params.view(1, -1)\n",
    "    accuracy, ece, logp = evaluate(params)\n",
    "    \n",
    "    accuracies.append(accuracy)\n",
    "    eces.append(ece)\n",
    "    logps.append(logp)\n",
    "    \n",
    "accuracies = np.array(accuracies)\n",
    "eces = np.array(eces)\n",
    "logps = np.array(logps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84b2cf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD_df = pd.DataFrame({\"Accuracy\": accuracies, \"ECE\": eces, \"log predictive\": logps})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98de7a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ECE</th>\n",
       "      <th>log predictive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9115</td>\n",
       "      <td>0.009907</td>\n",
       "      <td>-0.271943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9166</td>\n",
       "      <td>0.008780</td>\n",
       "      <td>-0.269324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9174</td>\n",
       "      <td>0.009571</td>\n",
       "      <td>-0.262576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9079</td>\n",
       "      <td>0.007665</td>\n",
       "      <td>-0.290798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9102</td>\n",
       "      <td>0.010044</td>\n",
       "      <td>-0.273837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy       ECE  log predictive\n",
       "0    0.9115  0.009907       -0.271943\n",
       "1    0.9166  0.008780       -0.269324\n",
       "2    0.9174  0.009571       -0.262576\n",
       "3    0.9079  0.007665       -0.290798\n",
       "4    0.9102  0.010044       -0.273837"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70c6d003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ECE</th>\n",
       "      <th>log predictive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.912720</td>\n",
       "      <td>0.009193</td>\n",
       "      <td>-0.273696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.004124</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>0.010468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.907900</td>\n",
       "      <td>0.007665</td>\n",
       "      <td>-0.290798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.910200</td>\n",
       "      <td>0.008780</td>\n",
       "      <td>-0.273837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.911500</td>\n",
       "      <td>0.009571</td>\n",
       "      <td>-0.271943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.916600</td>\n",
       "      <td>0.009907</td>\n",
       "      <td>-0.269324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.917400</td>\n",
       "      <td>0.010044</td>\n",
       "      <td>-0.262576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy       ECE  log predictive\n",
       "count  5.000000  5.000000        5.000000\n",
       "mean   0.912720  0.009193       -0.273696\n",
       "std    0.004124  0.000985        0.010468\n",
       "min    0.907900  0.007665       -0.290798\n",
       "25%    0.910200  0.008780       -0.273837\n",
       "50%    0.911500  0.009571       -0.271943\n",
       "75%    0.916600  0.009907       -0.269324\n",
       "max    0.917400  0.010044       -0.262576"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD_df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
