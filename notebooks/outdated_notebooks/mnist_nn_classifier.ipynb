{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchsde\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "# from torch import datasets\n",
    "\n",
    "from torch import _vmap_internals\n",
    "from torchvision import datasets, transforms\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cfollmer.objectives import log_g, relative_entropy_control_cost, stl_relative_entropy_control_cost_xu\n",
    "from cfollmer.sampler_utils import FollmerSDE\n",
    "from cfollmer.drifts import *\n",
    "from cfollmer.trainers import basic_batched_trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Model\n",
    "\n",
    "\\begin{align}\n",
    "\\theta &\\sim \\mathcal{N}(\\theta | 0, \\sigma_w^2 \\mathbb{I}) \\\\\n",
    "y_i | x_i, \\theta &\\sim  \\mathrm{Bernouli}\\left[\\mathrm{NN}_{\\theta}\\left(x_i \\right)\\right]\n",
    "\\end{align}\n",
    "\n",
    "We want samples from $p(\\theta | \\{(y_i, x_i)\\})$. Note $f(x; \\theta)$ is a neural net with params $\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train = datasets.MNIST(\"../data/mnist/\", download=True, train=True)\n",
    "images_test = datasets.MNIST(\"../data/mnist/\", download=True, train=False)\n",
    "\n",
    "transform = torch.nn.Sequential(transforms.Normalize((0.1307,), (0.3081)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = images_train.data, images_train.targets\n",
    "X_test, y_test = images_test.data, images_test.targets\n",
    "\n",
    "X_train = torch.flatten(transform(X_train.float()), 1)\n",
    "X_test = torch.flatten(transform(X_test.float()), 1)\n",
    "\n",
    "y_train = F.one_hot(y_train)\n",
    "y_test = F.one_hot(y_test)\n",
    "\n",
    "# X_train = np.concatenate((X_train, np.ones((X_train.shape[0],X_train.shape[1]))), axis=1)\n",
    "# X_test = np.concatenate((X_test, np.ones((X_test.shape[0],X_train.shape[1]))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-c969fd29504f>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(X_train, dtype=torch.float32, device=device), \\\n",
      "<ipython-input-5-c969fd29504f>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(X_test, dtype=torch.float32, device=device), \\\n",
      "<ipython-input-5-c969fd29504f>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(y_train, dtype=torch.float32, device=device), \\\n",
      "<ipython-input-5-c969fd29504f>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(y_test, dtype=torch.float32, device=device)\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    torch.tensor(X_train, dtype=torch.float32, device=device), \\\n",
    "    torch.tensor(X_test, dtype=torch.float32, device=device), \\\n",
    "    torch.tensor(y_train, dtype=torch.float32, device=device), \\\n",
    "    torch.tensor(y_test, dtype=torch.float32, device=device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 784])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\DeclareMathOperator*{\\argmin}{arg\\,min}$$\n",
    "$$\\def\\E{{\\mathbb{E}}}$$\n",
    "$$\\def\\rvu{{\\mathbf{u}}}$$\n",
    "$$\\def\\rvTheta{{\\bm{\\Theta}}}$$\n",
    "$$\\def\\gU{{\\mathcal{U}}}$$\n",
    "$$\\def\\mX{{\\mathbf{X}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controlled Schrodinger Follmer Sampler\n",
    "\n",
    "The objevtive we are trying to implement is:\n",
    "\n",
    "\\begin{align}\n",
    "  \\mathbf{u}_t^{*}=  \\argmin_{\\rvu_t \\in \\mathcal{U}}\\mathbb{E}\\left[\\frac{1}{2\\gamma}\\int_0^1||\\rvu(t, \\Theta_t)||^2 dt - \\ln\\left(\\frac{ p(\\mX | \\Theta_1)p(\\Theta_1)}{\\mathcal{N}(\\Theta_1|\\mathbf{0}, \\gamma \\mathbb{I} )}\\right)\\right] \\\n",
    "\\end{align}\n",
    "\n",
    "Where:\n",
    "\\begin{align}\n",
    "d\\Theta_t = \\rvu(t, \\Theta_t)dt + \\sqrt{\\gamma} dB_t\n",
    "\\end{align}\n",
    "\n",
    "To do so we use the EM discretisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ClassificationNetwork(object):\n",
    "    \n",
    "    def __init__(\n",
    "        self, input_dim=1, output_dim=1, depth=None,\n",
    "        width=20, width_seq=None, device=\"cpu\", activation=F.relu\n",
    "    ):\n",
    "        \n",
    "        self.device = device\n",
    "        self.output_dim = output_dim\n",
    "        self.input_dim = input_dim \n",
    "        self.activation = activation\n",
    "        \n",
    "        self.depth = depth\n",
    "        if not self.depth:\n",
    "            self.depth = 1\n",
    "        if not width_seq:\n",
    "            self.width = width\n",
    "            self.width_seq = [self.width] * (self.depth + 1)\n",
    "            self.shapes = [(self.width_seq[i-1], self.width_seq[i])  for i in range(1,self.depth)]\n",
    "            self.shapes += [(self.width_seq[-1], self.output_dim)]\n",
    "            self.shapes = [(self.input_dim, self.width_seq[0])] + self.shapes\n",
    "        \n",
    "        self.dim = sum([wx * wy + wy for wx, wy in self.shapes])\n",
    "        \n",
    "    def forward(self, x, Θ):\n",
    "        index = 0\n",
    "        n, d = x.shape\n",
    "        \n",
    "#         dim_bl =  sum([wx * wy + wy for wx, wy in self.shapes[:-1]])\n",
    "#         Θ[:dim_bl] = (Θ[:dim_bl] - Θ[:dim_bl].mean()) / Θ[:dim_bl].std()\n",
    "#         σ_Θ, μ_Θ = Θ.std(), Θ.mean()\n",
    "#         Θ = (Θ - μ_Θ) / σ_Θ\n",
    "\n",
    "        for wx, wy in self.shapes[:-1]:\n",
    "            x = F.linear(\n",
    "                x,\n",
    "                Θ[index: index + wx * wy].reshape(wy, wx),\n",
    "                Θ[index + wx * wy: index + wx * wy + wy].reshape(1,wy)\n",
    "            )\n",
    "            x = self.activation(x)\n",
    "            index += wx * wy  + wy\n",
    "        wx, wy = self.shapes[-1]\n",
    "        x = F.linear(\n",
    "            x,\n",
    "            Θ[index: index + wx * wy].reshape(wy, wx), #* σ_Θ + μ_Θ,\n",
    "            Θ[index + wx * wy: index + wx * wy + wy].reshape(1,wy) # * σ_Θ + μ_Θ\n",
    "        )\n",
    "        return x.to(self.device)\n",
    "    \n",
    "    def map_forward(self, x, Θ):\n",
    "        preds_func = lambda θ: self.forward(x, θ)\n",
    "        batched_preds = torch._vmap_internals.vmap(preds_func)\n",
    "        preds = torch.hstack(list(map(preds_func, Θ)))\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = X_train.shape[1]\n",
    "out_dim = y_train.shape[1]\n",
    "\n",
    "net = ClassificationNetwork(\n",
    "    dim, out_dim, device=device, depth=1, width=50, activation=F.tanh\n",
    ")\n",
    "\n",
    "\n",
    "def gaussian_prior(Θ, σ_w=3.8):\n",
    "    \"\"\"\n",
    "    Logistic regresion bayesian prior\n",
    "    \"\"\"\n",
    "    return -0.5 * (Θ**2).sum(axis=1) / σ_w\n",
    "\n",
    "\n",
    "def log_likelihood_vmap_nn(Θ, X, y, net=net):\n",
    "    \"\"\"\n",
    "    Hoping this implementation is less buggy / faster\n",
    "    \n",
    "    still feels a bit slow.\n",
    "    \"\"\"\n",
    "    \n",
    "    def loss(θ):\n",
    "        preds = net.forward(X, θ)\n",
    "        cel = torch.nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "#         import pdb; pdb.set_trace()\n",
    "        ll_cel = -1.0 * cel(preds, y.argmax(dim=1))\n",
    "        return ll_cel\n",
    "    \n",
    "    batched_loss =  torch._vmap_internals.vmap(loss)\n",
    "\n",
    "    return batched_loss(Θ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39760"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000e80b178ff47cf877689c500dac9f4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/scratch/home/fav25/ControlledFollmerDrift/cfollmer/objectives.py:143: UserWarning: torch.vmap is an experimental prototype that is subject to change and/or deletion. Please use at your own risk. There may be unexpected performance cliffs due to certain operators not being implemented. To see detailed performance warnings please use `torch._C._debug_only_display_vmap_fallback_warnings(True) before the call to `vmap`.\n",
      "  f = _vmap_internals.vmap(f_)\n",
      "/local/scratch/home/fav25/ControlledFollmerDrift/cfollmer/objectives.py:144: UserWarning: torch.vmap is an experimental prototype that is subject to change and/or deletion. Please use at your own risk. There may be unexpected performance cliffs due to certain operators not being implemented. To see detailed performance warnings please use `torch._C._debug_only_display_vmap_fallback_warnings(True) before the call to `vmap`.\n",
      "  f_detached = _vmap_internals.vmap(sde.f_detached)\n",
      "/local/scratch/home/fav25/ControlledFollmerDrift/cfollmer/objectives.py:152: UserWarning: torch.vmap is an experimental prototype that is subject to change and/or deletion. Please use at your own risk. There may be unexpected performance cliffs due to certain operators not being implemented. To see detailed performance warnings please use `torch._C._debug_only_display_vmap_fallback_warnings(True) before the call to `vmap`.\n",
      "  g = _vmap_internals.vmap(sde.g)\n",
      "<ipython-input-8-be3279387231>:30: UserWarning: torch.vmap is an experimental prototype that is subject to change and/or deletion. Please use at your own risk. There may be unexpected performance cliffs due to certain operators not being implemented. To see detailed performance warnings please use `torch._C._debug_only_display_vmap_fallback_warnings(True) before the call to `vmap`.\n",
      "  batched_loss =  torch._vmap_internals.vmap(loss)\n",
      "/home/fav25/.local/lib/python3.8/site-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3770670890808105\n",
      "2.1863701343536377\n",
      "2.005516529083252\n",
      "1.6569232940673828\n",
      "1.3457823991775513\n",
      "1.146380066871643\n",
      "0.9544356465339661\n",
      "0.828987717628479\n",
      "0.7359426021575928\n",
      "0.6586539149284363\n",
      "0.5723750591278076\n",
      "0.5308206081390381\n",
      "0.4964335560798645\n",
      "0.4613948464393616\n",
      "0.41332441568374634\n",
      "0.39699238538742065\n",
      "0.3962780833244324\n",
      "0.3923579752445221\n",
      "0.35848891735076904\n",
      "0.3654201626777649\n",
      "0.32917773723602295\n",
      "0.3504791557788849\n",
      "0.33872053027153015\n",
      "0.3236846923828125\n",
      "0.3243337571620941\n",
      "0.3130742311477661\n",
      "0.3227761685848236\n",
      "0.3165150284767151\n",
      "0.31513333320617676\n",
      "0.31661343574523926\n",
      "0.29742196202278137\n",
      "0.2974570095539093\n",
      "0.30057328939437866\n",
      "0.30576732754707336\n",
      "0.3074263334274292\n",
      "0.28385505080223083\n",
      "0.29548871517181396\n",
      "0.3094801902770996\n",
      "0.2861082851886749\n",
      "0.28496497869491577\n",
      "0.2873198091983795\n",
      "0.2715984582901001\n",
      "0.2797081768512726\n",
      "0.29713472723960876\n",
      "0.2939736843109131\n",
      "0.29375120997428894\n",
      "0.28445959091186523\n",
      "0.2784840762615204\n",
      "0.28768420219421387\n",
      "0.27820685505867004\n",
      "0.27226054668426514\n",
      "0.28426581621170044\n",
      "0.28468215465545654\n",
      "0.2703218460083008\n",
      "0.27081453800201416\n",
      "0.2609834372997284\n",
      "0.2778591215610504\n",
      "0.27768397331237793\n",
      "0.26419878005981445\n",
      "0.2887670397758484\n",
      "0.24598759412765503\n",
      "0.26529061794281006\n",
      "0.2722141146659851\n",
      "0.2683166563510895\n",
      "0.27142342925071716\n",
      "0.26191475987434387\n",
      "0.269707053899765\n",
      "0.27216488122940063\n",
      "0.2489825189113617\n",
      "0.2507188022136688\n",
      "0.24342603981494904\n",
      "0.2559380531311035\n",
      "0.2484971135854721\n",
      "0.23990465700626373\n",
      "0.2531616687774658\n",
      "0.24644878506660461\n",
      "0.25310108065605164\n",
      "0.2627120912075043\n",
      "0.2561471462249756\n",
      "0.2561856806278229\n",
      "0.2667142450809479\n",
      "0.2590910494327545\n",
      "0.24467585980892181\n",
      "0.2725905179977417\n",
      "0.25489065051078796\n",
      "0.24542665481567383\n",
      "0.24539409577846527\n",
      "0.23968243598937988\n",
      "0.23511043190956116\n",
      "0.25360390543937683\n",
      "0.24650028347969055\n",
      "0.23169977962970734\n",
      "0.24455244839191437\n",
      "0.24662987887859344\n",
      "0.24624189734458923\n",
      "0.23428931832313538\n",
      "0.24767740070819855\n",
      "0.23768506944179535\n",
      "0.2472761869430542\n",
      "0.23279839754104614\n",
      "0.24041056632995605\n",
      "0.2530815899372101\n",
      "0.24753203988075256\n",
      "0.22979888319969177\n",
      "0.2543557584285736\n",
      "0.23379823565483093\n",
      "0.23657512664794922\n",
      "0.24298308789730072\n",
      "0.21724991500377655\n",
      "0.2442023903131485\n",
      "0.23337283730506897\n",
      "0.2285902053117752\n",
      "0.2123374193906784\n",
      "0.2410821169614792\n",
      "0.20786207914352417\n",
      "0.23221848905086517\n",
      "0.22075426578521729\n",
      "0.22609378397464752\n",
      "0.22128520905971527\n",
      "0.21948060393333435\n",
      "0.23802122473716736\n",
      "0.2361726313829422\n",
      "0.21666672825813293\n",
      "0.2261905074119568\n",
      "0.24219931662082672\n",
      "0.24513652920722961\n",
      "0.23348087072372437\n",
      "0.22907604277133942\n",
      "0.23224423825740814\n",
      "0.22439652681350708\n",
      "0.22613592445850372\n",
      "0.22645197808742523\n",
      "0.23348374664783478\n",
      "0.24152936041355133\n",
      "0.24003289639949799\n",
      "0.23111993074417114\n",
      "0.2491626739501953\n",
      "0.23659995198249817\n",
      "0.22733712196350098\n",
      "0.24321267008781433\n",
      "0.2534855008125305\n",
      "0.21976731717586517\n",
      "0.24374708533287048\n",
      "0.24605804681777954\n",
      "0.2256333827972412\n",
      "0.2384244203567505\n",
      "0.22401297092437744\n",
      "0.23391099274158478\n",
      "0.22404631972312927\n",
      "0.24439045786857605\n",
      "0.2421136051416397\n",
      "0.22506213188171387\n",
      "0.2355397343635559\n",
      "0.225271075963974\n",
      "0.2387121170759201\n",
      "0.23744675517082214\n",
      "0.23890596628189087\n",
      "0.2433251142501831\n",
      "0.23942258954048157\n",
      "0.2403792440891266\n",
      "0.23808282613754272\n",
      "0.2377949208021164\n",
      "0.22013503313064575\n",
      "0.24291060864925385\n",
      "0.22773082554340363\n",
      "0.21763896942138672\n",
      "0.23886115849018097\n",
      "0.22507654130458832\n",
      "0.22411797940731049\n",
      "0.21453329920768738\n",
      "0.22563707828521729\n",
      "0.22145503759384155\n",
      "0.20734599232673645\n",
      "0.20742680132389069\n",
      "0.20916259288787842\n",
      "0.2244996726512909\n",
      "0.22623026371002197\n",
      "0.21211287379264832\n",
      "0.21153806149959564\n",
      "0.23802340030670166\n",
      "0.24202489852905273\n",
      "0.2214781939983368\n",
      "0.2111789584159851\n",
      "0.23414115607738495\n",
      "0.22392886877059937\n",
      "0.24190984666347504\n",
      "0.20013433694839478\n",
      "0.22895900905132294\n",
      "0.21900513768196106\n",
      "0.21849389374256134\n",
      "0.21820752322673798\n",
      "0.22375166416168213\n",
      "0.20359684526920319\n",
      "0.22696225345134735\n",
      "0.2061384618282318\n",
      "0.2187628149986267\n",
      "0.20472930371761322\n",
      "0.22114497423171997\n",
      "0.22017987072467804\n",
      "0.23507489264011383\n",
      "0.21708005666732788\n",
      "0.21247068047523499\n",
      "0.2210300862789154\n",
      "0.22727221250534058\n",
      "0.23032468557357788\n",
      "0.1979924440383911\n",
      "0.21653865277767181\n",
      "0.23370163142681122\n",
      "0.24236881732940674\n",
      "0.23169346153736115\n",
      "0.2510874271392822\n",
      "0.23820054531097412\n",
      "0.19949331879615784\n",
      "0.22931447625160217\n",
      "0.23242343962192535\n",
      "0.22658228874206543\n",
      "0.23572611808776855\n",
      "0.23893143236637115\n",
      "0.21720652282238007\n",
      "0.21717922389507294\n",
      "0.21199148893356323\n",
      "0.22558334469795227\n",
      "0.22055932879447937\n",
      "0.21420429646968842\n",
      "0.24341493844985962\n",
      "0.2080707848072052\n",
      "0.22922423481941223\n",
      "0.21393057703971863\n",
      "0.2212357521057129\n",
      "0.2179993838071823\n",
      "0.21821030974388123\n",
      "0.2253318428993225\n",
      "0.22530899941921234\n",
      "0.22054241597652435\n",
      "0.21719351410865784\n",
      "0.19995954632759094\n",
      "0.2111138552427292\n",
      "0.22463010251522064\n",
      "0.24538905918598175\n",
      "0.20477385818958282\n",
      "0.20941229164600372\n",
      "0.22261181473731995\n",
      "0.25003132224082947\n",
      "0.2224467396736145\n",
      "0.21941380202770233\n",
      "0.23637056350708008\n",
      "0.23289692401885986\n",
      "0.2278335988521576\n",
      "0.22571961581707\n",
      "0.2225751280784607\n",
      "0.22287991642951965\n",
      "0.22273682057857513\n",
      "0.2220742404460907\n"
     ]
    }
   ],
   "source": [
    "class SimpleForwardNetBN_larger(AbstractDrift):\n",
    "\n",
    "    def __init__(self, input_dim=1, width=300, activation=torch.nn.Softplus):\n",
    "        super(SimpleForwardNetBN_larger, self).__init__()\n",
    "        \n",
    "        self.nn = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_dim + 1, width), torch.nn.BatchNorm1d(width, affine=False), activation(),\n",
    "            torch.nn.Linear(width, width), torch.nn.BatchNorm1d(width, affine=False), activation(),\n",
    "            torch.nn.Linear(width, width), torch.nn.BatchNorm1d(width, affine=False), activation(),\n",
    "            torch.nn.Linear(width, width), torch.nn.BatchNorm1d(width, affine=False), activation(),\n",
    "            torch.nn.Linear(width, input_dim )\n",
    "        )\n",
    "        \n",
    "        self.nn[-1].weight.data.fill_(0.0)\n",
    "\n",
    "\n",
    "γ =  0.1**2\n",
    "Δt=0.01\n",
    "\n",
    "dim= net.dim\n",
    "\n",
    "prior = gaussian_prior\n",
    "\n",
    "sde, losses = basic_batched_trainer(\n",
    "    γ, Δt, prior, log_likelihood_vmap_nn, dim, X_train, y_train,\n",
    "    method=\"euler\", stl=\"stl_xu\", adjoint=False, optimizer=None,\n",
    "    num_steps=79, batch_size_data=int(X_train.shape[0] // 5), batch_size_Θ=30,\n",
    "    batchnorm=True, device=device, lr=0.0001, drift=SimpleForwardNetBN_larger, schedule=\"uniform\",\n",
    "    γ_min= 0.1**2, γ_max= 0.4**2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_size = int(math.ceil(1.0/Δt))\n",
    "ts = torch.linspace(0, 1, t_size).to(device)\n",
    "no_posterior_samples = 100\n",
    "Θ_0 = torch.zeros((no_posterior_samples, net.dim)).to(device)\n",
    "\n",
    "Θ_1 = torchsde.sdeint(sde, Θ_0, ts, dt=Δt)[-1,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2,ax3) = plt.subplots(1,3)\n",
    "\n",
    "ax1.hist(Θ_1[:,0].cpu().detach().numpy())\n",
    "ax2.hist(Θ_1[:,1].cpu().detach().numpy())\n",
    "ax3.hist(Θ_1[:,2].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predc(X, Θ):\n",
    "    return torch.vstack([(net.forward(X, θ)[None,...]).softmax(dim=-1) for θ in Θ]).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predc(X_train, Θ_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "((pred.argmax(dim=-1)).float().flatten()== y_train.argmax(dim=-1)).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = predc(X_test.float(), Θ_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((pred_test.argmax(dim=-1)).float().flatten()== y_test.argmax(dim=-1)).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAP Baseline\n",
    "\n",
    "We run the point estimate approximation (Maximum a posteriori) to double check what the learned weights look like.  We get the  exact same training accuracy as with the controlled model and similarly large weights for the non bias weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Θ_map = torch.zeros((1, dim), requires_grad=True, device=device)\n",
    "optimizer_map = torch.optim.Adam([Θ_map], lr=0.05)\n",
    "#     optimizer = torch.optim.LBFGS(gpr.parameters(), lr=0.01)\n",
    "\n",
    "losses_map = []\n",
    "num_steps = 1000\n",
    "for i in tqdm(range(num_steps)):\n",
    "    optimizer_map.zero_grad()\n",
    "\n",
    "    if isinstance(optimizer_map, torch.optim.LBFGS):\n",
    "        def closure_map():\n",
    "            loss_map = log_likelihood_vmap()\n",
    "            optimizer_map.zero_grad()\n",
    "            loss_map.backward()\n",
    "            return loss\n",
    "\n",
    "        optimizer_map.step(closure_map)\n",
    "        losses_map.append(closure_map().item())\n",
    "    else:\n",
    "        loss_map = -(log_likelihood_vmap(Θ_map, X_train, y_train) + gaussian_prior(Θ_map))\n",
    "        optimizer_map.zero_grad()\n",
    "        loss_map.backward()\n",
    "        print(loss_map.item())\n",
    "        optimizer_map.step()\n",
    "        losses_map.append(loss_map.item())\n",
    "\n",
    "Θ_map\n",
    "pred_map = torch.sigmoid(X_train.mm(Θ_map.T)).mean(axis=1)\n",
    "((pred_map < 0.5).float() == y_train).float().mean(), Θ_map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
