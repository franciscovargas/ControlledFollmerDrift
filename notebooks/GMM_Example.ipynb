{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchsde\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cfollmer.objectives import log_g, relative_entropy_control_cost\n",
    "from cfollmer.sampler_utils import FollmerSDE\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from torch import _vmap_internals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Toy 2D Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "random_state = 170\n",
    "\n",
    "X, y = make_blobs(n_samples=100,\n",
    "                  cluster_std=[0.2, 0.2, 0.2],\n",
    "                  random_state=random_state)\n",
    "\n",
    "# X = X[y==0,:]\n",
    "# y = y[y==0]\n",
    "# # Scale data to have mean 0 and variance 1 \n",
    "# # which is importance for convergence of the neural network\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data set into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=2)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    torch.tensor(X_train, dtype=torch.float32, device=device), \\\n",
    "    torch.tensor(X_test, dtype=torch.float32, device=device), \\\n",
    "    torch.tensor(y_train, dtype=torch.float32, device=device), \\\n",
    "    torch.tensor(y_test, dtype=torch.float32, device=device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, 0, 0, 1, 1, 0, 2, 1, 1, 1, 0, 1, 0, 2, 1, 1, 1, 2, 2, 2,\n",
       "       2, 2, 1, 1, 0, 2, 0, 1, 2, 0, 1, 2, 1, 0, 0, 0, 0, 0, 2, 0, 2, 0,\n",
       "       0, 1, 2, 2, 0, 1, 2, 2, 1, 2, 0, 1, 2, 1, 0, 0, 1, 0, 0, 2, 0, 2,\n",
       "       2, 1, 1, 1, 2, 0, 1, 0, 0, 0, 2, 1, 1, 1, 1, 1, 2, 1, 0, 0, 1, 2,\n",
       "       2, 1, 2, 2, 1, 0, 2, 2, 0, 0, 0, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, figsize=(16, 6))\n",
    "\n",
    "ax1.plot(X_scaled[:, 0], X_scaled[:, 1], \n",
    "         linestyle='none', \n",
    "         marker='o')\n",
    "\n",
    "ax1.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\DeclareMathOperator*{\\argmin}{arg\\,min}$$\n",
    "$$\\def\\E{{\\mathbb{E}}}$$\n",
    "$$\\def\\rvu{{\\mathbf{u}}}$$\n",
    "$$\\def\\rvTheta{{\\bm{\\Theta}}}$$\n",
    "$$\\def\\gU{{\\mathcal{U}}}$$\n",
    "$$\\def\\mX{{\\mathbf{X}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controlled Schrodinger Follmer Sampler\n",
    "\n",
    "The objevtive we are trying to implement is:\n",
    "\n",
    "\\begin{align}\n",
    "  \\mathbf{u}_t^{*}=  \\argmin_{\\rvu_t \\in \\mathcal{U}}\\mathbb{E}\\left[\\frac{1}{2\\gamma}\\int_0^1||\\rvu(t, \\Theta_t)||^2 dt - \\ln\\left(\\frac{ p(\\mX | \\Theta_1)p(\\Theta_1)}{\\mathcal{N}(\\Theta_1|\\mathbf{0}, \\gamma \\mathbb{I} )}\\right)\\right] \\\n",
    "\\end{align}\n",
    "\n",
    "Where:\n",
    "\\begin{align}\n",
    "d\\Theta_t = \\rvu(t, \\Theta_t)dt + \\sqrt{\\gamma} dB_t\n",
    "\\end{align}\n",
    "\n",
    "To do so we use the EM discretisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_gaussian(x, mean=0):\n",
    "    \"\"\"\n",
    "    Returns the density of x under the supplied gaussian. Defaults to\n",
    "    standard gaussian N(0, I)\n",
    "    :param x: (*) torch.Tensor\n",
    "    :param mean: float or torch.FloatTensor with dimensions (*)\n",
    "    :param logvar: float or torch.FloatTensor with dimensions (*)\n",
    "    :return: (*) elementwise log density\n",
    "    \"\"\"\n",
    "    \n",
    "    log_norm_constant = -0.5 * np.log(2 * np.pi)\n",
    "    \n",
    "    var =  torch.tensor(0.2)\n",
    "    logvar = torch.log(var)\n",
    "    logvar = x.new(1).fill_(logvar)\n",
    "    \n",
    "    A = (x - mean) ** 2\n",
    "    log_p = -0.5 * (logvar + A / logvar.exp())\n",
    "    log_p = log_p + log_norm_constant\n",
    "#     import pdb; pdb.set_trace()\n",
    "    return log_p.sum(dim=-1)\n",
    "\n",
    "\n",
    "\n",
    "def ln_prior(Θ, σ_w=2):\n",
    "    \"\"\"\n",
    "    Prior for means in Bayesian GMM\n",
    "    \"\"\"\n",
    "    return -0.5 * (Θ**2).sum(axis=1) / σ_w\n",
    "\n",
    "\n",
    "def log_likelihood_single(μ, X, log=True, K=3):\n",
    "    \"\"\"\n",
    "    :param X: design matrix (examples, features)\n",
    "    :param mu: the component means (K, features)\n",
    "    :param logvar: the component log-variances (K, features)\n",
    "    :param log: return value in log domain?\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    n, d = X.shape\n",
    "    # get feature-wise log-likelihoods (K, examples, features)\n",
    "#     import pdb; pdb.set_trace()\n",
    "    log_likelihoods = log_gaussian(\n",
    "        X[None, :, :], # (1, examples, features)\n",
    "        μ.reshape(K, d)[:, None, :], # (K, 1, features)\n",
    "    )\n",
    "    \n",
    "\n",
    "    # sum over the feature dimension\n",
    "    \n",
    "    log_likelihoods = torch.logsumexp(log_likelihoods, dim=0) \n",
    "\n",
    "    return log_likelihoods.sum()\n",
    "\n",
    "\n",
    "def log_likelihood(Θ, X, y=None, K=3):\n",
    "    \"\"\"\n",
    "    batching the above (hopefully its right)\n",
    "    \"\"\"\n",
    "\n",
    "    loss_ = lambda μ: log_likelihood_single(μ, X,K=K)\n",
    "    \n",
    "    batched_loss =  torch._vmap_internals.vmap(loss_)\n",
    "\n",
    "    return batched_loss(Θ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "Δt=0.05\n",
    "K = 3\n",
    "t_size = int(math.ceil(1.0/Δt))\n",
    "dim = K * 2\n",
    "\n",
    "ts = torch.linspace(0, 1, t_size).to(device)\n",
    "no_posterior_samples = 50\n",
    "\n",
    "sde = FollmerSDE(dim, dim, no_posterior_samples, 1.0, device=device).to(device)\n",
    "Θ_0 = torch.zeros((no_posterior_samples, dim)).to(device) # Θ_0 ~ δ_0\n",
    "\n",
    "# Initial state y0, the SDE is solved over the interval [ts[0], ts[-1]].\n",
    "# ys will have shape (t_size, batch_size, state_size)\n",
    "ys = torchsde.sdeint(sde, Θ_0, ts, dt=Δt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vargf\\anaconda3\\lib\\site-packages\\torch\\_vmap_internals.py:252: UserWarning: torch.vmap is an experimental prototype that is subject to change and/or deletion. Please use at your own risk.\n",
      "  warnings.warn(\n",
      "<ipython-input-108-2548c0f873f6>:52: UserWarning: Batching rule not implemented for aten::logsumexp falling back to slow (for loop and stack) implementation (Triggered internally at  ..\\aten\\src\\ATen\\BatchedFallback.cpp:63.)\n",
      "  log_likelihoods = torch.logsumexp(log_likelihoods, dim=0)\n",
      "<ipython-input-108-2548c0f873f6>:54: UserWarning: Batching rule not implemented for aten::sum falling back to slow (for loop and stack) implementation (Triggered internally at  ..\\aten\\src\\ATen\\BatchedFallback.cpp:63.)\n",
      "  return log_likelihoods.sum()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(311.9275, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_entropy_control_cost(sde, Θ_0, X_train, y_train, \n",
    "                              ln_prior, log_likelihood, γ=1.0, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f9d246396a4af1b6de46279f6da325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vargf\\anaconda3\\lib\\site-packages\\torch\\_vmap_internals.py:252: UserWarning: torch.vmap is an experimental prototype that is subject to change and/or deletion. Please use at your own risk.\n",
      "  warnings.warn(\n",
      "<ipython-input-108-2548c0f873f6>:52: UserWarning: Batching rule not implemented for aten::logsumexp falling back to slow (for loop and stack) implementation (Triggered internally at  ..\\aten\\src\\ATen\\BatchedFallback.cpp:63.)\n",
      "  log_likelihoods = torch.logsumexp(log_likelihoods, dim=0)\n",
      "<ipython-input-108-2548c0f873f6>:54: UserWarning: Batching rule not implemented for aten::sum falling back to slow (for loop and stack) implementation (Triggered internally at  ..\\aten\\src\\ATen\\BatchedFallback.cpp:63.)\n",
      "  return log_likelihoods.sum()\n"
     ]
    }
   ],
   "source": [
    "γ = 1.0\n",
    "Δt=0.01\n",
    "t_size = int(math.ceil(1.0/Δt))\n",
    "print(t_size)\n",
    "ts = torch.linspace(0, 1, t_size).to(device)\n",
    "\n",
    "sde = FollmerSDE(dim, dim, no_posterior_samples  , γ=γ, device=device).to(device)\n",
    "optimizer = torch.optim.Adam(sde.μ.parameters(), lr=0.05, weight_decay =1)\n",
    "#     optimizer = torch.optim.LBFGS(gpr.parameters(), lr=0.01)\n",
    "losses = []\n",
    "num_steps = 300\n",
    "for i in tqdm(range(num_steps)):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if isinstance(optimizer, torch.optim.LBFGS):\n",
    "        def closure():\n",
    "            loss = relative_entropy_control_cost(\n",
    "                sde, Θ_0.float(),\n",
    "                X_train.float(), y_train.float(),\n",
    "                ln_prior, log_likelihood, γ=γ\n",
    "            )\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            return loss\n",
    "\n",
    "        optimizer.step(closure)\n",
    "        losses.append(closure().item())\n",
    "    else:\n",
    "        loss = relative_entropy_control_cost(\n",
    "            sde, Θ_0,\n",
    "            X_train, y_train,\n",
    "            ln_prior, log_likelihood, γ=γ\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " torchsde.sdeint(sde, Θ_0, ts, method=\"euler\", dt=Δt).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Θ_1 = torchsde.sdeint(sde, Θ_0, ts, dt=Δt)[-1,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Θ_1 = Θ_1.reshape(50,K,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2)\n",
    "\n",
    "ax1.hist(Θ_1[:,:,0].flatten().cpu().detach().numpy())\n",
    "ax2.hist(Θ_1[:,:,1].flatten().cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Θ_1.mean(axis=0).reshape(K,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Θ_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_1 = plt.subplots(1, 1, figsize=(16, 6))\n",
    "Θ_plot = Θ_1.cpu().detach() #.reshape(50*3,2)\n",
    "\n",
    "\n",
    "for i in range(K):\n",
    "    ax_1.plot(Θ_plot[:,i, 0], Θ_plot[:, i, 1], \n",
    "             linestyle='none', \n",
    "             marker='o', color=\"red\", label=\"posterior $\\mu$ samples\")\n",
    "\n",
    "ax_1.plot(X_scaled[:, 0], X_scaled[:, 1], \n",
    "         linestyle='none', \n",
    "         marker='o', label=\"Observations $X$\")\n",
    "\n",
    "ax_1.legend()\n",
    "ax_1.axis('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
